{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc5a1ef-47b1-48c4-a596-b8740d92e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Leggendo i dati di test...\n",
      "Test size: 116323\n",
      "Numero di classi uniche nel dataset di test: 62\n",
      "Etichette uniche nel dataset di test: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "Inizio la ricerca dei campioni richiesti...\n",
      "Checkpoint caricato per LeNet5: No Norm: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Checkpoint caricato per KaNet5: No Norm: results/results_None_SGD_lr0.01_5_3/KaNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Checkpoint caricato per LeNet5: L2 Norm: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Checkpoint caricato per KaNet5: L2 Norm: results/results_L2_SGD_lr0.01_5_3/KaNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Trovato campione 0 che sbaglia tutti i modelli.\n",
      "Trovato campione 1 che non sbaglia nessun modello.\n",
      "Trovato campione 2 che non sbaglia nessun modello.\n",
      "Trovato campione 49 che sbaglia solo il modello 2.\n",
      "Trovato campione 52 che sbaglia solo il modello 3.\n",
      "Trovato campione 65 che sbaglia solo il modello 1.\n",
      "Trovato campione 100 che sbaglia solo il modello 4.\n",
      "Tutti i campioni richiesti sono stati trovati.\n",
      "Tutti i campioni richiesti per la categoria 'misclass_model_1_only' sono stati trovati.\n",
      "Tutti i campioni richiesti per la categoria 'misclass_model_2_only' sono stati trovati.\n",
      "Tutti i campioni richiesti per la categoria 'misclass_model_3_only' sono stati trovati.\n",
      "Tutti i campioni richiesti per la categoria 'misclass_model_4_only' sono stati trovati.\n",
      "Tutti i campioni richiesti per la categoria 'misclass_all' sono stati trovati.\n",
      "Tutti i campioni richiesti per la categoria 'correct_all' sono stati trovati.\n",
      "\n",
      "Indici dei campioni selezionati: [0, 1, 2, 49, 52, 65, 100]\n",
      "\n",
      "Sample 0 - Correct Class: I (Index: 18), Predicted Class: 1 (Index: 1) by LeNet5: No Norm\n",
      "Sample 1 - Correct Class: a (Index: 36), Predicted Class: a (Index: 36) by LeNet5: No Norm\n",
      "Sample 2 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by LeNet5: No Norm\n",
      "Sample 49 - Correct Class: 6 (Index: 6), Predicted Class: 6 (Index: 6) by LeNet5: No Norm\n",
      "Sample 52 - Correct Class: l (Index: 47), Predicted Class: l (Index: 47) by LeNet5: No Norm\n",
      "Sample 65 - Correct Class: t (Index: 55), Predicted Class: y (Index: 60) by LeNet5: No Norm\n",
      "Sample 100 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by LeNet5: No Norm\n",
      "Predizioni salvate in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/predictions.csv\n",
      "Sample 0 - Correct Class: I (Index: 18), Predicted Class: 1 (Index: 1) by KaNet5: No Norm\n",
      "Sample 1 - Correct Class: a (Index: 36), Predicted Class: a (Index: 36) by KaNet5: No Norm\n",
      "Sample 2 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by KaNet5: No Norm\n",
      "Sample 49 - Correct Class: 6 (Index: 6), Predicted Class: b (Index: 37) by KaNet5: No Norm\n",
      "Sample 52 - Correct Class: l (Index: 47), Predicted Class: l (Index: 47) by KaNet5: No Norm\n",
      "Sample 65 - Correct Class: t (Index: 55), Predicted Class: t (Index: 55) by KaNet5: No Norm\n",
      "Sample 100 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by KaNet5: No Norm\n",
      "Predizioni salvate in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/predictions.csv\n",
      "Sample 0 - Correct Class: I (Index: 18), Predicted Class: 1 (Index: 1) by LeNet5: L2 Norm\n",
      "Sample 1 - Correct Class: a (Index: 36), Predicted Class: a (Index: 36) by LeNet5: L2 Norm\n",
      "Sample 2 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by LeNet5: L2 Norm\n",
      "Sample 49 - Correct Class: 6 (Index: 6), Predicted Class: 6 (Index: 6) by LeNet5: L2 Norm\n",
      "Sample 52 - Correct Class: l (Index: 47), Predicted Class: t (Index: 55) by LeNet5: L2 Norm\n",
      "Sample 65 - Correct Class: t (Index: 55), Predicted Class: t (Index: 55) by LeNet5: L2 Norm\n",
      "Sample 100 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by LeNet5: L2 Norm\n",
      "Predizioni salvate in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/predictions.csv\n",
      "Sample 0 - Correct Class: I (Index: 18), Predicted Class: 1 (Index: 1) by KaNet5: L2 Norm\n",
      "Sample 1 - Correct Class: a (Index: 36), Predicted Class: a (Index: 36) by KaNet5: L2 Norm\n",
      "Sample 2 - Correct Class: 0 (Index: 0), Predicted Class: 0 (Index: 0) by KaNet5: L2 Norm\n",
      "Sample 49 - Correct Class: 6 (Index: 6), Predicted Class: 6 (Index: 6) by KaNet5: L2 Norm\n",
      "Sample 52 - Correct Class: l (Index: 47), Predicted Class: l (Index: 47) by KaNet5: L2 Norm\n",
      "Sample 65 - Correct Class: t (Index: 55), Predicted Class: t (Index: 55) by KaNet5: L2 Norm\n",
      "Sample 100 - Correct Class: 0 (Index: 0), Predicted Class: O (Index: 24) by KaNet5: L2 Norm\n",
      "Predizioni salvate in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "selected_indices = set()\n",
    "# -------------------------\n",
    "# Definizione dei Modelli\n",
    "# -------------------------\n",
    "\n",
    "# Importazione dei modelli KAN\n",
    "# Assicurati che il pacchetto 'kan_convolutional' sia installato e accessibile\n",
    "try:\n",
    "    from kan_convolutional.KANLinear import KANLinear\n",
    "    import kan_convolutional.convolution\n",
    "    from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "except ImportError:\n",
    "    raise ImportError(\"Il pacchetto 'kan_convolutional' non è stato trovato. Assicurati di averlo installato correttamente.\")\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)       # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)             # 14x14 -> 10x10\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)       # 10x10 -> 5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)                   # Flatten\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LeNet5_KAN(nn.Module):\n",
    "    def __init__(self, num_classes=62):  # EMNIST Balanced ha 62 classi\n",
    "        super(LeNet5_KAN, self).__init__()\n",
    "        \n",
    "        # Primo strato conv: input=1 canale, output=6 filtri, kernel=5x5\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=(5,5),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            dilation=(1,1),\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.ReLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=(-1, 1)\n",
    "        )\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Secondo strato conv: input=6 canali, output=16 filtri, kernel=5x5\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=(5,5),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            dilation=(1,1),\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.ReLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=(-1, 1)\n",
    "        )\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Dopo conv1+pool1 (28x28 -> conv5x5->24x24 -> pool->12x12)\n",
    "        # Dopo conv2+pool2 (12x12 -> conv5x5->8x8 -> pool->4x4)\n",
    "        # 16 canali da 4x4 => 16*4*4=256\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passo 1: conv + pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Passo 2: conv + pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers con ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output Layer (senza attivazione)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Dataset in Memoria\n",
    "# -------------------------\n",
    "\n",
    "class EMNISTMemoryDataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor):\n",
    "        self.data = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# -------------------------\n",
    "# Funzioni per leggere i file IDX\n",
    "# -------------------------\n",
    "\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\"Legge immagini in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\"Legge etichette in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# -------------------------\n",
    "# Funzione di Denormalizzazione\n",
    "# -------------------------\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "# -------------------------\n",
    "# Mappatura delle Classi\n",
    "# -------------------------\n",
    "\n",
    "def get_emnist_class_mapping():\n",
    "    \"\"\"\n",
    "    Mappatura delle classi EMNIST ai caratteri corrispondenti.\n",
    "    EMNIST ByClass ha 62 classi: 0-9, 10-35 A-Z, 36-61 a-z\n",
    "    \"\"\"\n",
    "    characters = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    return {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Estrarre un Campione Specifico\n",
    "# -------------------------\n",
    "\n",
    "def get_sample_by_index(dataset, index):\n",
    "    \"\"\"\n",
    "    Estrae un campione specifico dal dataset utilizzando un indice.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): Il dataset da cui estrarre il campione.\n",
    "        index (int): L'indice del campione da estrarre.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (sample_data, sample_target)\n",
    "    \"\"\"\n",
    "    if index < 0 or index >= len(dataset):\n",
    "        raise IndexError(\"Indice fuori dal range del dataset.\")\n",
    "    sample_data, sample_target = dataset[index]\n",
    "    return sample_data.unsqueeze(0), sample_target  # Aggiungi dimensione batch\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Generare e Salvataggio delle Classi Predette e Corrette\n",
    "# -------------------------\n",
    "\n",
    "def save_predicted_and_correct_class(sample_index, model, model_name, gradcam_dir, class_mapping, device, test_dataset, csv_writer):\n",
    "    \"\"\"\n",
    "    Genera la predizione per un campione usando un modello e salva la classe predetta e corretta in un file CSV.\n",
    "    \n",
    "    Args:\n",
    "        sample_index (int): Indice del campione nel dataset di test.\n",
    "        model (nn.Module): Modello caricato.\n",
    "        model_name (str): Nome del modello (es. \"LeNet5: No Norm\").\n",
    "        gradcam_dir (str): Directory dove salvare il file CSV.\n",
    "        class_mapping (dict): Dizionario mappatura indice classe -> carattere/numero.\n",
    "        device (torch.device): Dispositivo (CPU o CUDA).\n",
    "        test_dataset (Dataset): Dataset di test.\n",
    "        csv_writer (csv.writer): Writer per il file CSV.\n",
    "    \"\"\"\n",
    "    # Estrai il campione\n",
    "    sample_data, sample_target = get_sample_by_index(test_dataset, sample_index)\n",
    "    sample_data = sample_data.to(device)\n",
    "    \n",
    "    # Predizione\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_data)\n",
    "    pred_class_idx = output.argmax(dim=1).item()\n",
    "    pred_class_char = class_mapping.get(pred_class_idx, \"Unknown\")\n",
    "    \n",
    "    # Classe corretta\n",
    "    correct_class_idx = sample_target.item()\n",
    "    correct_class_char = class_mapping.get(correct_class_idx, \"Unknown\")\n",
    "    \n",
    "    # Debugging: Stampa le classi per verifica\n",
    "    print(f\"Sample {sample_index} - Correct Class: {correct_class_char} (Index: {correct_class_idx}), Predicted Class: {pred_class_char} (Index: {pred_class_idx}) by {model_name}\")\n",
    "    \n",
    "    # Scrivi nel CSV\n",
    "    csv_writer.writerow([sample_index, correct_class_char, pred_class_char, model_name])\n",
    "\n",
    "# -------------------------\n",
    "# Funzione Principale\n",
    "# -------------------------\n",
    "\n",
    "def main():\n",
    "    # Impostazioni\n",
    "    learning_rate = 0.01\n",
    "    optimizer_type = \"SGD\"\n",
    "    grid_size = 5\n",
    "    spline_order = 3\n",
    "    norm_type = \"L2\"\n",
    "    num_of_classes = 62\n",
    "    batch_size = 1  # Rimuovere il batching\n",
    "\n",
    "    seed = 12\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "    mean, std = 0.1307, 0.3081\n",
    "\n",
    "    data_dir = '/home/magliolo/.cache/emnist/gzip/'  # Modifica questo percorso se necessario\n",
    "\n",
    "    # Definizione dei modelli e delle loro directory\n",
    "    model_configs = [\n",
    "        {\n",
    "            \"name\": \"LeNet5: No Norm\",\n",
    "            \"gradcam_dir\": \"results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/\",\n",
    "            \"model_dir\": \"results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/model/\",\n",
    "            \"model_class\": LeNet5\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KaNet5: No Norm\",\n",
    "            \"gradcam_dir\": \"results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/\",\n",
    "            \"model_dir\": \"results/results_None_SGD_lr0.01_5_3/KaNet5/model/\",\n",
    "            \"model_class\": LeNet5_KAN\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"LeNet5: L2 Norm\",\n",
    "            \"gradcam_dir\": \"results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/\",\n",
    "            \"model_dir\": \"results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/model/\",\n",
    "            \"model_class\": LeNet5\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KaNet5: L2 Norm\",\n",
    "            \"gradcam_dir\": \"results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/\",\n",
    "            \"model_dir\": \"results/results_L2_SGD_lr0.01_5_3/KaNet5/model/\",\n",
    "            \"model_class\": LeNet5_KAN\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Controllo che tutte le directory GradCAM esistano\n",
    "    for config in model_configs:\n",
    "        os.makedirs(config[\"gradcam_dir\"], exist_ok=True)\n",
    "\n",
    "    # Carica la mappatura delle classi\n",
    "    class_mapping = get_emnist_class_mapping()\n",
    "\n",
    "    # Carica i dati di test\n",
    "    test_images_path = os.path.join(data_dir, 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    test_labels_path = os.path.join(data_dir, 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    print(\"Leggendo i dati di test...\")\n",
    "    images_test = read_idx_images(test_images_path)\n",
    "    labels_test = read_idx_labels(test_labels_path)\n",
    "\n",
    "    # Converti in Tensori e normalizza\n",
    "    test_images_tensor = torch.from_numpy(images_test.copy()).unsqueeze(1).float()\n",
    "    test_labels_tensor = torch.from_numpy(labels_test.copy()).long()\n",
    "\n",
    "    # Normalizzazione\n",
    "    test_images_tensor = (test_images_tensor - mean) / std\n",
    "\n",
    "    # Sposta su GPU\n",
    "    test_images_tensor = test_images_tensor.to(device)\n",
    "    test_labels_tensor = test_labels_tensor.to(device)\n",
    "\n",
    "    # Crea il dataset in memoria\n",
    "    test_dataset = EMNISTMemoryDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "    # Crea il DataLoader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Test size: {len(test_loader.dataset)}\")\n",
    "    print(f\"Numero di classi uniche nel dataset di test: {len(set(labels_test))}\")\n",
    "    print(f\"Etichette uniche nel dataset di test: {sorted(set(labels_test))}\")\n",
    "\n",
    "    # Definizione delle categorie richieste\n",
    "    required_categories = {\n",
    "        \"misclass_model_1_only\": [],\n",
    "        \"misclass_model_2_only\": [],\n",
    "        \"misclass_model_3_only\": [],\n",
    "        \"misclass_model_4_only\": [],\n",
    "        \"misclass_all\": [],\n",
    "        \"correct_all\": []\n",
    "    }\n",
    "\n",
    "    # Numero di esempi per ogni categoria\n",
    "    required_counts = {\n",
    "        \"misclass_model_1_only\": 1,\n",
    "        \"misclass_model_2_only\": 1,\n",
    "        \"misclass_model_3_only\": 1,\n",
    "        \"misclass_model_4_only\": 1,\n",
    "        \"misclass_all\": 1,\n",
    "        \"correct_all\": 2\n",
    "    }\n",
    "\n",
    "    # Flags per sapere quando abbiamo trovato tutto\n",
    "    found = {\n",
    "        \"misclass_model_1_only\": 0,\n",
    "        \"misclass_model_2_only\": 0,\n",
    "        \"misclass_model_3_only\": 0,\n",
    "        \"misclass_model_4_only\": 0,\n",
    "        \"misclass_all\": 0,\n",
    "        \"correct_all\": 0\n",
    "    }\n",
    "\n",
    "    print(\"Inizio la ricerca dei campioni richiesti...\")\n",
    "\n",
    "    # Carica tutti i modelli\n",
    "    loaded_models = []\n",
    "    for config in model_configs:\n",
    "        model_name = config[\"name\"]\n",
    "        gradcam_dir = config[\"gradcam_dir\"]\n",
    "        model_dir = config[\"model_dir\"]\n",
    "        model_class = config[\"model_class\"]\n",
    "\n",
    "        # Inizializza il modello\n",
    "        model = model_class(num_classes=num_of_classes).to(device)\n",
    "\n",
    "        # Trova il checkpoint_epoch_50.pth\n",
    "        checkpoint_path = os.path.join(model_dir, \"checkpoint_epoch_50.pth\")\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            print(f\"Checkpoint non trovato per {model_name} in {checkpoint_path}. Salto questo modello.\")\n",
    "            continue\n",
    "\n",
    "        # Carica il checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        epoch = checkpoint.get('epoch', 'Unknown')\n",
    "        print(f\"Checkpoint caricato per {model_name}: {checkpoint_path}, Epoch: {epoch}\")\n",
    "        model.eval()\n",
    "\n",
    "        # Aggiungi il modello alla lista\n",
    "        loaded_models.append({\n",
    "            \"name\": model_name,\n",
    "            \"model\": model,\n",
    "            \"gradcam_dir\": gradcam_dir\n",
    "        })\n",
    "\n",
    "    if len(loaded_models) < 4:\n",
    "        print(\"Non tutti i modelli sono stati caricati correttamente. Verifica i checkpoint e le configurazioni.\")\n",
    "        return\n",
    "\n",
    "    # Itera su ogni campione del dataset di test\n",
    "    for idx in range(len(test_dataset)):\n",
    "        if all(found[cat] >= required_counts[cat] for cat in required_categories):\n",
    "            print(\"Tutti i campioni richiesti sono stati trovati.\")\n",
    "            break\n",
    "\n",
    "        sample_data, sample_target = get_sample_by_index(test_dataset, idx)\n",
    "        sample_data = sample_data.to(device)\n",
    "\n",
    "        # Predizioni di tutti i modelli\n",
    "        pred_classes = []\n",
    "        for loaded_model in loaded_models:\n",
    "            model = loaded_model[\"model\"]\n",
    "            with torch.no_grad():\n",
    "                output = model(sample_data)\n",
    "            pred_class_idx = output.argmax(dim=1).item()\n",
    "            pred_class_char = class_mapping.get(pred_class_idx, \"Unknown\")\n",
    "            pred_classes.append(pred_class_char)\n",
    "\n",
    "        # Classe corretta\n",
    "        correct_class_idx = sample_target.item()\n",
    "        correct_class_char = class_mapping.get(correct_class_idx, \"Unknown\")\n",
    "\n",
    "        # Determina quali modelli hanno sbagliato\n",
    "        misclass_flags = [pred != correct_class_char for pred in pred_classes]\n",
    "\n",
    "        # Categorie specifiche\n",
    "        misclass_model_1 = misclass_flags[0]\n",
    "        misclass_model_2 = misclass_flags[1]\n",
    "        misclass_model_3 = misclass_flags[2]\n",
    "        misclass_model_4 = misclass_flags[3]\n",
    "\n",
    "        # Controlla le categorie\n",
    "        if (misclass_model_1 and not misclass_model_2 and not misclass_model_3 and not misclass_model_4 and\n",
    "            found[\"misclass_model_1_only\"] < required_counts[\"misclass_model_1_only\"]):\n",
    "            required_categories[\"misclass_model_1_only\"].append(idx)\n",
    "            found[\"misclass_model_1_only\"] += 1\n",
    "            print(f\"Trovato campione {idx} che sbaglia solo il modello 1.\")\n",
    "            continue\n",
    "\n",
    "        if (misclass_model_2 and not misclass_model_1 and not misclass_model_3 and not misclass_model_4 and\n",
    "            found[\"misclass_model_2_only\"] < required_counts[\"misclass_model_2_only\"]):\n",
    "            required_categories[\"misclass_model_2_only\"].append(idx)\n",
    "            found[\"misclass_model_2_only\"] += 1\n",
    "            print(f\"Trovato campione {idx} che sbaglia solo il modello 2.\")\n",
    "            continue\n",
    "\n",
    "        if (misclass_model_3 and not misclass_model_1 and not misclass_model_2 and not misclass_model_4 and\n",
    "            found[\"misclass_model_3_only\"] < required_counts[\"misclass_model_3_only\"]):\n",
    "            required_categories[\"misclass_model_3_only\"].append(idx)\n",
    "            found[\"misclass_model_3_only\"] += 1\n",
    "            print(f\"Trovato campione {idx} che sbaglia solo il modello 3.\")\n",
    "            continue\n",
    "\n",
    "        if (misclass_model_4 and not misclass_model_1 and not misclass_model_2 and not misclass_model_3 and\n",
    "            found[\"misclass_model_4_only\"] < required_counts[\"misclass_model_4_only\"]):\n",
    "            required_categories[\"misclass_model_4_only\"].append(idx)\n",
    "            found[\"misclass_model_4_only\"] += 1\n",
    "            print(f\"Trovato campione {idx} che sbaglia solo il modello 4.\")\n",
    "            continue\n",
    "\n",
    "        # Campione che sbaglia tutti i modelli\n",
    "        if (misclass_model_1 and misclass_model_2 and misclass_model_3 and misclass_model_4 and\n",
    "            found[\"misclass_all\"] < required_counts[\"misclass_all\"]):\n",
    "            required_categories[\"misclass_all\"].append(idx)\n",
    "            found[\"misclass_all\"] += 1\n",
    "            print(f\"Trovato campione {idx} che sbaglia tutti i modelli.\")\n",
    "            continue\n",
    "\n",
    "        # Campione che non sbaglia nessun modello\n",
    "        if (not misclass_model_1 and not misclass_model_2 and not misclass_model_3 and not misclass_model_4 and\n",
    "            found[\"correct_all\"] < required_counts[\"correct_all\"]):\n",
    "            required_categories[\"correct_all\"].append(idx)\n",
    "            found[\"correct_all\"] += 1\n",
    "            print(f\"Trovato campione {idx} che non sbaglia nessun modello.\")\n",
    "            continue\n",
    "\n",
    "    # Verifica se tutte le categorie sono state trovate\n",
    "    for cat, count in required_counts.items():\n",
    "        if found[cat] < count:\n",
    "            print(f\"Attenzione: Solo {found[cat]} campioni trovati per la categoria '{cat}', richiesta {count}.\")\n",
    "        else:\n",
    "            print(f\"Tutti i campioni richiesti per la categoria '{cat}' sono stati trovati.\")\n",
    "\n",
    "    # Unisci tutti gli indici raccolti\n",
    "    global selected_indices\n",
    "    for cat in required_categories:\n",
    "        selected_indices.update(required_categories[cat])\n",
    "\n",
    "    selected_indices = sorted(list(selected_indices))\n",
    "    print(f\"\\nIndici dei campioni selezionati: {selected_indices}\\n\")\n",
    "\n",
    "    # Itera su ogni modello e salva le predizioni e classi corrette per i campioni selezionati\n",
    "    for loaded_model in loaded_models:\n",
    "        model_name = loaded_model[\"name\"]\n",
    "        model = loaded_model[\"model\"]\n",
    "        gradcam_dir = loaded_model[\"gradcam_dir\"]\n",
    "\n",
    "        # Prepara il file CSV\n",
    "        csv_filename = \"predictions.csv\"\n",
    "        csv_path = os.path.join(gradcam_dir, csv_filename)\n",
    "        with open(csv_path, mode='w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            # Scrivi l'intestazione\n",
    "            csv_writer.writerow([\"sample_index\", \"correct_class\", \"predicted_class\", \"model_name\"])\n",
    "\n",
    "            # Itera su ogni sample_index\n",
    "            for sample_index in selected_indices:\n",
    "                try:\n",
    "                    save_predicted_and_correct_class(\n",
    "                        sample_index=sample_index,\n",
    "                        model=model,\n",
    "                        model_name=model_name,\n",
    "                        gradcam_dir=gradcam_dir,\n",
    "                        class_mapping=class_mapping,\n",
    "                        device=device,\n",
    "                        test_dataset=test_dataset,\n",
    "                        csv_writer=csv_writer\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore nella predizione per sample {sample_index} con {model_name}: {e}\")\n",
    "\n",
    "        print(f\"Predizioni salvate in: {csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42720d85-c3f7-4ff5-80d4-3e0dd6eb6abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Checkpoint caricato: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Leggendo i dati di test...\n",
      "Test size: 116323\n",
      "Numero di classi uniche nel dataset di test: 62\n",
      "Etichette uniche nel dataset di test: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "Directory per GradCAM: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM\n",
      "\n",
      "Generando Grad-CAM per l'indice: 0\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 1\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 2\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 49\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 52\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 65\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 100\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_chart.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import struct\n",
    "import random\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Modello\n",
    "# -------------------------\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)       # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)             # 14x14 -> 10x10\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)       # 10x10 -> 5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)                   # Flatten\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Dataset in Memoria\n",
    "# -------------------------\n",
    "\n",
    "class EMNISTMemoryDataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor):\n",
    "        self.data = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# -------------------------\n",
    "# Funzioni per leggere i file IDX\n",
    "# -------------------------\n",
    "\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\"Legge immagini in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\"Legge etichette in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# -------------------------\n",
    "# Funzione di Denormalizzazione\n",
    "# -------------------------\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "# -------------------------\n",
    "# Mappatura delle Classi\n",
    "# -------------------------\n",
    "\n",
    "def get_emnist_class_mapping():\n",
    "    \"\"\"\n",
    "    Mappatura delle classi EMNIST ai caratteri corrispondenti.\n",
    "    EMNIST ByClass ha 62 classi: 0-9, 10-35 A-Z, 36-61 a-z\n",
    "    \"\"\"\n",
    "    characters = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    return {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Estrarre un Campione Specifico\n",
    "# -------------------------\n",
    "\n",
    "def get_sample_by_index(dataset, index):\n",
    "    \"\"\"\n",
    "    Estrae un campione specifico dal dataset utilizzando un indice.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): Il dataset da cui estrarre il campione.\n",
    "        index (int): L'indice del campione da estrarre.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (sample_data, sample_target)\n",
    "    \"\"\"\n",
    "    if index < 0 or index >= len(dataset):\n",
    "        raise IndexError(\"Indice fuori dal range del dataset.\")\n",
    "    sample_data, sample_target = dataset[index]\n",
    "    return sample_data.unsqueeze(0), sample_target  # Aggiungi dimensione batch\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Sovrapporre la Heatmap con un Alpha Regolabile\n",
    "# -------------------------\n",
    "\n",
    "def overlay_heatmap_on_image(original, heatmap, alpha=0.6, colormap='jet'):\n",
    "    \"\"\"\n",
    "    Sovrappone una heatmap su un'immagine originale con un parametro alpha regolabile.\n",
    "    \n",
    "    Args:\n",
    "        original (numpy.ndarray): Immagine originale in formato RGB e normalizzata tra 0 e 1.\n",
    "        heatmap (numpy.ndarray): Heatmap normalizzata tra 0 e 1.\n",
    "        alpha (float): Trasparenza della heatmap.\n",
    "        colormap (str): Colormap da utilizzare per la heatmap.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Immagine con la heatmap sovrapposta.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB) / 255.0  # Converti da BGR a RGB e normalizza\n",
    "    overlay = (1 - alpha) * original + alpha * heatmap_color\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    return overlay\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Generare e Visualizzare Grad-CAM\n",
    "# -------------------------\n",
    "\n",
    "def generate_gradcam_plots(sample_index, gradcam_dir):\n",
    "    \"\"\"\n",
    "    Genera e salva le heatmap Grad-CAM per un campione specifico.\n",
    "    \n",
    "    Args:\n",
    "        sample_index (int): L'indice del campione da analizzare.\n",
    "        gradcam_dir (str): Directory dove salvare le immagini Grad-CAM.\n",
    "    \"\"\"\n",
    "    # Verifica che l'indice sia valido\n",
    "    if sample_index < 0 or sample_index >= len(test_dataset):\n",
    "        raise IndexError(f\"Indice {sample_index} fuori dal range del dataset.\")\n",
    "    \n",
    "    # Estrai il campione specifico\n",
    "    sample_data, sample_target = get_sample_by_index(test_dataset, sample_index)\n",
    "    sample_data = sample_data.to(device)\n",
    "    sample_target = sample_target.item()\n",
    "    \n",
    "    # Definisci il target layer\n",
    "    target_layer = model.conv2\n",
    "    \n",
    "    # Inizializza GradCAM senza use_cuda\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    \n",
    "    # Genera la heatmap Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=sample_data, targets=None)  # None = classe predetta\n",
    "    grayscale_cam = grayscale_cam[0]  # Rimuovi dimensione batch\n",
    "    \n",
    "    # Normalizza la heatmap tra 0 e 1\n",
    "    grayscale_cam_normalized = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-8)\n",
    "    \n",
    "    # Ottieni la classe predetta\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_data)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Denormalizza l'immagine originale per visualizzazione\n",
    "    original_image = denormalize(sample_data.cpu().clone(), [mean], [std]).squeeze().numpy()\n",
    "    \n",
    "    # Flip orizzontale e rotazione di 90 gradi anti-clockwise\n",
    "    original_image = np.fliplr(original_image)  # Flip orizzontale\n",
    "    original_image = np.rot90(original_image, k=1)  # Rotazione di 90 gradi anti-clockwise\n",
    "    \n",
    "    grayscale_cam_normalized = np.fliplr(grayscale_cam_normalized)  # Flip orizzontale della heatmap\n",
    "    grayscale_cam_normalized = np.rot90(grayscale_cam_normalized, k=1)  # Rotazione di 90 gradi anti-clockwise della heatmap\n",
    "    \n",
    "    # Converti l'immagine originale in RGB e normalizzala tra 0 e 1\n",
    "    original_image_rgb = np.stack([original_image]*3, axis=2)  # [H, W, 3]\n",
    "    original_image_rgb = original_image_rgb / 255.0  # Assicurati che l'immagine sia tra 0 e 1\n",
    "    \n",
    "    # Sovrapponi manualmente la heatmap con un alpha maggiore\n",
    "    visualization = overlay_heatmap_on_image(original_image_rgb, grayscale_cam_normalized, alpha=0.6)\n",
    "    \n",
    "    # Salva separatamente le tre tipologie di immagini\n",
    "    \n",
    "    # 1. Immagine Originale\n",
    "    original_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_original.png')\n",
    "    plt.imsave(original_save_path, original_image, cmap='gray')\n",
    "    \n",
    "    # 2. Heatmap Grad-CAM\n",
    "    heatmap_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_heatmap.png')\n",
    "    plt.imsave(heatmap_save_path, grayscale_cam_normalized, cmap='jet')\n",
    "    \n",
    "    # 3. Immagine con Heatmap Sovrapposta\n",
    "    overlay_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_overlay.png')\n",
    "    plt.imsave(overlay_save_path, visualization)\n",
    "    \n",
    "    # 4. Grafico Completo\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    \n",
    "    # Plot 1: Immagine Originale\n",
    "    axs[0].imshow(original_image, cmap='gray')\n",
    "    axs[0].set_title(f\"Immagine Originale - Classe Vera: {class_mapping[sample_target]}\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot 2: Heatmap Grad-CAM\n",
    "    im = axs[1].imshow(grayscale_cam_normalized, cmap='jet')\n",
    "    axs[1].set_title(\"Heatmap Grad-CAM\")\n",
    "    axs[1].axis('off')\n",
    "    # Aggiungi una barra laterale (colorbar)\n",
    "    cbar = fig.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel('Intensità', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Plot 3: Immagine con Heatmap Sovrapposta\n",
    "    axs[2].imshow(visualization)\n",
    "    axs[2].set_title(f\"Classe Predetta: {class_mapping[pred_class]}\")\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    # Salva il grafico completo\n",
    "    chart_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_chart.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(chart_save_path)\n",
    "    plt.close(fig)  # Chiudi la figura per liberare memoria\n",
    "    \n",
    "    print(f\"Immagine Originale salvata in: {original_save_path}\")\n",
    "    print(f\"Heatmap Grad-CAM salvata in: {heatmap_save_path}\")\n",
    "    print(f\"Immagine con Heatmap Sovrapposta salvata in: {overlay_save_path}\")\n",
    "    print(f\"Grafico Completo salvato in: {chart_save_path}\")\n",
    "    \n",
    "    # Pulisci i hook dopo aver finito\n",
    "    cam = None  # Libera risorse (GradCAM chiama automaticamente remove hooks nel suo metodo __del__)\n",
    "\n",
    "# -------------------------\n",
    "# Funzione Principale\n",
    "# -------------------------\n",
    "\n",
    "def main():\n",
    "    global model, test_dataset, class_mapping, mean, std, base_dir, device\n",
    "\n",
    "    # Impostazione dei parametri fissi\n",
    "    learning_rate = 0.01\n",
    "    optimizer_type = \"SGD\"\n",
    "    grid_size = 0\n",
    "    spline_order = 0\n",
    "    norm_type = \"None\"\n",
    "    num_of_classes = 62\n",
    "    batch_size = 1  # Rimuovere il batching\n",
    "\n",
    "    # Seme per riproducibilità\n",
    "    seed = 12\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "    mean, std = 0.1307, 0.3081\n",
    "\n",
    "    data_dir = '/home/magliolo/.cache/emnist/gzip/'\n",
    "\n",
    "    base_dir = os.path.join(\n",
    "        'results',\n",
    "        f\"results_{norm_type}_{optimizer_type}_lr{learning_rate}_{grid_size}_{spline_order}\",\n",
    "        'Standard_LeNet5'\n",
    "    )\n",
    "    model_dir = os.path.join(base_dir, \"model\")\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Directory del modello non trovata: {model_dir}\")\n",
    "\n",
    "    model = LeNet5(num_classes=num_of_classes).to(device)\n",
    "\n",
    "    checkpoints = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError(f\"Nessun checkpoint trovato nella directory: {model_dir}\")\n",
    "    try:\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    except ValueError:\n",
    "        # Se il formato del checkpoint è diverso, usa semplicemente il file più recente\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: os.path.getctime(os.path.join(model_dir, x)))\n",
    "    checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Checkpoint caricato: {checkpoint_path}, Epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "    model.eval()\n",
    "\n",
    "    # Leggi i dati di test\n",
    "    test_images_path = os.path.join(data_dir, 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    test_labels_path = os.path.join(data_dir, 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    print(\"Leggendo i dati di test...\")\n",
    "    images_test = read_idx_images(test_images_path)\n",
    "    labels_test = read_idx_labels(test_labels_path)\n",
    "\n",
    "    # Converti in Tensori e normalizza\n",
    "    test_images_tensor = torch.from_numpy(images_test.copy()).unsqueeze(1).float()\n",
    "    test_labels_tensor = torch.from_numpy(labels_test.copy()).long()\n",
    "\n",
    "    # Normalizzazione\n",
    "    test_images_tensor = (test_images_tensor - mean) / std\n",
    "\n",
    "    # Sposta su GPU\n",
    "    test_images_tensor = test_images_tensor.to(device)\n",
    "    test_labels_tensor = test_labels_tensor.to(device)\n",
    "\n",
    "    # Crea il dataset in memoria\n",
    "    test_dataset = EMNISTMemoryDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "    # Crea il DataLoader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Test size: {len(test_loader.dataset)}\")\n",
    "    print(f\"Numero di classi uniche nel dataset di test: {len(set(labels_test))}\")\n",
    "    print(f\"Etichette uniche nel dataset di test: {sorted(set(labels_test))}\")\n",
    "\n",
    "    # Mappatura delle classi\n",
    "    class_mapping = get_emnist_class_mapping()\n",
    "\n",
    "    # Crea la subfolder \"GradCAM\" all'interno di base_dir\n",
    "    gradcam_dir = os.path.join(base_dir, \"GradCAM\")\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    print(f\"Directory per GradCAM: {gradcam_dir}\")\n",
    "\n",
    "    # Ora puoi chiamare la funzione `generate_gradcam_plots` con l'indice desiderato\n",
    "    # Esempio:\n",
    "    sample_indices = selected_indices  # Puoi aggiungere altri indici qui\n",
    "\n",
    "    for sample_index in sample_indices:\n",
    "        print(f\"\\nGenerando Grad-CAM per l'indice: {sample_index}\")\n",
    "        try:\n",
    "            generate_gradcam_plots(sample_index, gradcam_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nella generazione della heatmap per l'indice {sample_index}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bb885c-2cda-4bdc-ac86-026fc032b4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Checkpoint caricato: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Leggendo i dati di test...\n",
      "Test size: 116323\n",
      "Numero di classi uniche nel dataset di test: 62\n",
      "Etichette uniche nel dataset di test: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "Directory per GradCAM: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM\n",
      "\n",
      "Generando Grad-CAM per l'indice: 0\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_0_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 1\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_1_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 2\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_2_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 49\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_49_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 52\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_52_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 65\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_65_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 100\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_0_0/Standard_LeNet5/GradCAM/sample_100_chart.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import struct\n",
    "import random\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Modello\n",
    "# -------------------------\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28 -> 28x28\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)       # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)             # 14x14 -> 10x10\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)       # 10x10 -> 5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)                   # Flatten\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Dataset in Memoria\n",
    "# -------------------------\n",
    "\n",
    "class EMNISTMemoryDataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor):\n",
    "        self.data = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# -------------------------\n",
    "# Funzioni per leggere i file IDX\n",
    "# -------------------------\n",
    "\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\"Legge immagini in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\"Legge etichette in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# -------------------------\n",
    "# Funzione di Denormalizzazione\n",
    "# -------------------------\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "# -------------------------\n",
    "# Mappatura delle Classi\n",
    "# -------------------------\n",
    "\n",
    "def get_emnist_class_mapping():\n",
    "    \"\"\"\n",
    "    Mappatura delle classi EMNIST ai caratteri corrispondenti.\n",
    "    EMNIST ByClass ha 62 classi: 0-9, 10-35 A-Z, 36-61 a-z\n",
    "    \"\"\"\n",
    "    characters = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    return {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Estrarre un Campione Specifico\n",
    "# -------------------------\n",
    "\n",
    "def get_sample_by_index(dataset, index):\n",
    "    \"\"\"\n",
    "    Estrae un campione specifico dal dataset utilizzando un indice.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): Il dataset da cui estrarre il campione.\n",
    "        index (int): L'indice del campione da estrarre.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (sample_data, sample_target)\n",
    "    \"\"\"\n",
    "    if index < 0 or index >= len(dataset):\n",
    "        raise IndexError(\"Indice fuori dal range del dataset.\")\n",
    "    sample_data, sample_target = dataset[index]\n",
    "    return sample_data.unsqueeze(0), sample_target  # Aggiungi dimensione batch\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Sovrapporre la Heatmap con un Alpha Regolabile\n",
    "# -------------------------\n",
    "\n",
    "def overlay_heatmap_on_image(original, heatmap, alpha=0.6, colormap='jet'):\n",
    "    \"\"\"\n",
    "    Sovrappone una heatmap su un'immagine originale con un parametro alpha regolabile.\n",
    "    \n",
    "    Args:\n",
    "        original (numpy.ndarray): Immagine originale in formato RGB e normalizzata tra 0 e 1.\n",
    "        heatmap (numpy.ndarray): Heatmap normalizzata tra 0 e 1.\n",
    "        alpha (float): Trasparenza della heatmap.\n",
    "        colormap (str): Colormap da utilizzare per la heatmap.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Immagine con la heatmap sovrapposta.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB) / 255.0  # Converti da BGR a RGB e normalizza\n",
    "    overlay = (1 - alpha) * original + alpha * heatmap_color\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    return overlay\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Generare e Visualizzare Grad-CAM\n",
    "# -------------------------\n",
    "\n",
    "def generate_gradcam_plots(sample_index, gradcam_dir):\n",
    "    \"\"\"\n",
    "    Genera e salva le heatmap Grad-CAM per un campione specifico.\n",
    "    \n",
    "    Args:\n",
    "        sample_index (int): L'indice del campione da analizzare.\n",
    "        gradcam_dir (str): Directory dove salvare le immagini Grad-CAM.\n",
    "    \"\"\"\n",
    "    # Verifica che l'indice sia valido\n",
    "    if sample_index < 0 or sample_index >= len(test_dataset):\n",
    "        raise IndexError(f\"Indice {sample_index} fuori dal range del dataset.\")\n",
    "    \n",
    "    # Estrai il campione specifico\n",
    "    sample_data, sample_target = get_sample_by_index(test_dataset, sample_index)\n",
    "    sample_data = sample_data.to(device)\n",
    "    sample_target = sample_target.item()\n",
    "    \n",
    "    # Definisci il target layer\n",
    "    target_layer = model.conv2\n",
    "    \n",
    "    # Inizializza GradCAM senza use_cuda\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    \n",
    "    # Genera la heatmap Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=sample_data, targets=None)  # None = classe predetta\n",
    "    grayscale_cam = grayscale_cam[0]  # Rimuovi dimensione batch\n",
    "    \n",
    "    # Normalizza la heatmap tra 0 e 1\n",
    "    grayscale_cam_normalized = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-8)\n",
    "    \n",
    "    # Ottieni la classe predetta\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_data)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Denormalizza l'immagine originale per visualizzazione\n",
    "    original_image = denormalize(sample_data.cpu().clone(), [mean], [std]).squeeze().numpy()\n",
    "    \n",
    "    # Flip orizzontale e rotazione di 90 gradi anti-clockwise\n",
    "    original_image = np.fliplr(original_image)  # Flip orizzontale\n",
    "    original_image = np.rot90(original_image, k=1)  # Rotazione di 90 gradi anti-clockwise\n",
    "    \n",
    "    grayscale_cam_normalized = np.fliplr(grayscale_cam_normalized)  # Flip orizzontale della heatmap\n",
    "    grayscale_cam_normalized = np.rot90(grayscale_cam_normalized, k=1)  # Rotazione di 90 gradi anti-clockwise della heatmap\n",
    "    \n",
    "    # Converti l'immagine originale in RGB e normalizzala tra 0 e 1\n",
    "    original_image_rgb = np.stack([original_image]*3, axis=2)  # [H, W, 3]\n",
    "    original_image_rgb = original_image_rgb / 255.0  # Assicurati che l'immagine sia tra 0 e 1\n",
    "    \n",
    "    # Sovrapponi manualmente la heatmap con un alpha maggiore\n",
    "    visualization = overlay_heatmap_on_image(original_image_rgb, grayscale_cam_normalized, alpha=0.6)\n",
    "    \n",
    "    # Salva separatamente le tre tipologie di immagini\n",
    "    \n",
    "    # 1. Immagine Originale\n",
    "    original_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_original.png')\n",
    "    plt.imsave(original_save_path, original_image, cmap='gray')\n",
    "    \n",
    "    # 2. Heatmap Grad-CAM\n",
    "    heatmap_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_heatmap.png')\n",
    "    plt.imsave(heatmap_save_path, grayscale_cam_normalized, cmap='jet')\n",
    "    \n",
    "    # 3. Immagine con Heatmap Sovrapposta\n",
    "    overlay_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_overlay.png')\n",
    "    plt.imsave(overlay_save_path, visualization)\n",
    "    \n",
    "    # 4. Grafico Completo\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    \n",
    "    # Plot 1: Immagine Originale\n",
    "    axs[0].imshow(original_image, cmap='gray')\n",
    "    axs[0].set_title(f\"Immagine Originale - Classe Vera: {class_mapping[sample_target]}\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot 2: Heatmap Grad-CAM\n",
    "    im = axs[1].imshow(grayscale_cam_normalized, cmap='jet')\n",
    "    axs[1].set_title(\"Heatmap Grad-CAM\")\n",
    "    axs[1].axis('off')\n",
    "    # Aggiungi una barra laterale (colorbar)\n",
    "    cbar = fig.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel('Intensità', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Plot 3: Immagine con Heatmap Sovrapposta\n",
    "    axs[2].imshow(visualization)\n",
    "    axs[2].set_title(f\"Classe Predetta: {class_mapping[pred_class]}\")\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    # Salva il grafico completo\n",
    "    chart_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_chart.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(chart_save_path)\n",
    "    plt.close(fig)  # Chiudi la figura per liberare memoria\n",
    "    \n",
    "    print(f\"Immagine Originale salvata in: {original_save_path}\")\n",
    "    print(f\"Heatmap Grad-CAM salvata in: {heatmap_save_path}\")\n",
    "    print(f\"Immagine con Heatmap Sovrapposta salvata in: {overlay_save_path}\")\n",
    "    print(f\"Grafico Completo salvato in: {chart_save_path}\")\n",
    "    \n",
    "    # Pulisci i hook dopo aver finito\n",
    "    cam = None  # Libera risorse (GradCAM chiama automaticamente remove hooks nel suo metodo __del__)\n",
    "\n",
    "# -------------------------\n",
    "# Funzione Principale\n",
    "# -------------------------\n",
    "\n",
    "def main():\n",
    "    global model, test_dataset, class_mapping, mean, std, base_dir, device\n",
    "\n",
    "    # Impostazione dei parametri fissi\n",
    "    learning_rate = 0.01\n",
    "    optimizer_type = \"SGD\"\n",
    "    grid_size = 0\n",
    "    spline_order = 0\n",
    "    norm_type = \"L2\"\n",
    "    num_of_classes = 62\n",
    "    batch_size = 1  # Rimuovere il batching\n",
    "\n",
    "    # Seme per riproducibilità\n",
    "    seed = 12\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "    mean, std = 0.1307, 0.3081\n",
    "\n",
    "    data_dir = '/home/magliolo/.cache/emnist/gzip/'\n",
    "\n",
    "    base_dir = os.path.join(\n",
    "        'results',\n",
    "        f\"results_{norm_type}_{optimizer_type}_lr{learning_rate}_{grid_size}_{spline_order}\",\n",
    "        'Standard_LeNet5'\n",
    "    )\n",
    "    model_dir = os.path.join(base_dir, \"model\")\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Directory del modello non trovata: {model_dir}\")\n",
    "\n",
    "    model = LeNet5(num_classes=num_of_classes).to(device)\n",
    "\n",
    "    checkpoints = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError(f\"Nessun checkpoint trovato nella directory: {model_dir}\")\n",
    "    try:\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    except ValueError:\n",
    "        # Se il formato del checkpoint è diverso, usa semplicemente il file più recente\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: os.path.getctime(os.path.join(model_dir, x)))\n",
    "    checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Checkpoint caricato: {checkpoint_path}, Epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "    model.eval()\n",
    "\n",
    "    # Leggi i dati di test\n",
    "    test_images_path = os.path.join(data_dir, 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    test_labels_path = os.path.join(data_dir, 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    print(\"Leggendo i dati di test...\")\n",
    "    images_test = read_idx_images(test_images_path)\n",
    "    labels_test = read_idx_labels(test_labels_path)\n",
    "\n",
    "    # Converti in Tensori e normalizza\n",
    "    test_images_tensor = torch.from_numpy(images_test.copy()).unsqueeze(1).float()\n",
    "    test_labels_tensor = torch.from_numpy(labels_test.copy()).long()\n",
    "\n",
    "    # Normalizzazione\n",
    "    test_images_tensor = (test_images_tensor - mean) / std\n",
    "\n",
    "    # Sposta su GPU\n",
    "    test_images_tensor = test_images_tensor.to(device)\n",
    "    test_labels_tensor = test_labels_tensor.to(device)\n",
    "\n",
    "    # Crea il dataset in memoria\n",
    "    test_dataset = EMNISTMemoryDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "    # Crea il DataLoader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Test size: {len(test_loader.dataset)}\")\n",
    "    print(f\"Numero di classi uniche nel dataset di test: {len(set(labels_test))}\")\n",
    "    print(f\"Etichette uniche nel dataset di test: {sorted(set(labels_test))}\")\n",
    "\n",
    "    # Mappatura delle classi\n",
    "    class_mapping = get_emnist_class_mapping()\n",
    "\n",
    "    # Crea la subfolder \"GradCAM\" all'interno di base_dir\n",
    "    gradcam_dir = os.path.join(base_dir, \"GradCAM\")\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    print(f\"Directory per GradCAM: {gradcam_dir}\")\n",
    "\n",
    "    # Ora puoi chiamare la funzione `generate_gradcam_plots` con l'indice desiderato\n",
    "    # Esempio:\n",
    "    sample_indices = selected_indices  # Puoi aggiungere altri indici qui\n",
    "\n",
    "    for sample_index in sample_indices:\n",
    "        print(f\"\\nGenerando Grad-CAM per l'indice: {sample_index}\")\n",
    "        try:\n",
    "            generate_gradcam_plots(sample_index, gradcam_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nella generazione della heatmap per l'indice {sample_index}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa8447b-dc1e-46a1-85bf-52295ba9af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Checkpoint caricato: results/results_L2_SGD_lr0.01_5_3/KaNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Leggendo i dati di test...\n",
      "Test size: 116323\n",
      "Numero di classi uniche nel dataset di test: 62\n",
      "Etichette uniche nel dataset di test: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "Directory per GradCAM: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM\n",
      "\n",
      "Generando Grad-CAM per l'indice: 0\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 1\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 2\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 49\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 52\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 65\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 100\n",
      "Immagine Originale salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_overlay.png\n",
      "Grafico Completo salvato in: results/results_L2_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_chart.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import struct\n",
    "import random\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Modello KAN\n",
    "# -------------------------\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "import kan_convolutional.convolution\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "\n",
    "class LeNet5_KAN(nn.Module):\n",
    "    def __init__(self, num_classes=62):  # EMNIST Balanced ha 62 classi\n",
    "        super(LeNet5_KAN, self).__init__()\n",
    "        \n",
    "        # Primo strato conv: input=1 canale, output=6 filtri, kernel=5x5\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=(5,5),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            dilation=(1,1),\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.ReLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=(-1, 1)\n",
    "        )\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Secondo strato conv: input=6 canali, output=16 filtri, kernel=5x5\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=(5,5),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            dilation=(1,1),\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.ReLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=(-1, 1)\n",
    "        )\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Dopo conv1+pool1 (28x28 -> conv5x5->24x24 -> pool->12x12)\n",
    "        # Dopo conv2+pool2 (12x12 -> conv5x5->8x8 -> pool->4x4)\n",
    "        # 16 canali da 4x4 => 16*4*4=256\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passo 1: conv + pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Passo 2: conv + pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers con ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output Layer (senza attivazione)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Dataset in Memoria\n",
    "# -------------------------\n",
    "\n",
    "class EMNISTMemoryDataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor):\n",
    "        self.data = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# -------------------------\n",
    "# Funzioni per leggere i file IDX\n",
    "# -------------------------\n",
    "\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\"Legge immagini in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\"Legge etichette in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# -------------------------\n",
    "# Funzione di Denormalizzazione\n",
    "# -------------------------\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "# -------------------------\n",
    "# Mappatura delle Classi\n",
    "# -------------------------\n",
    "\n",
    "def get_emnist_class_mapping():\n",
    "    characters = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    return {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Estrarre un Campione Specifico\n",
    "# -------------------------\n",
    "\n",
    "def get_sample_by_index(dataset, index):\n",
    "    if index < 0 or index >= len(dataset):\n",
    "        raise IndexError(\"Indice fuori dal range del dataset.\")\n",
    "    sample_data, sample_target = dataset[index]\n",
    "    return sample_data.unsqueeze(0), sample_target  # Aggiungi dimensione batch\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Sovrapporre la Heatmap con un Alpha Regolabile\n",
    "# -------------------------\n",
    "\n",
    "def overlay_heatmap_on_image(original, heatmap, alpha=0.6, colormap='jet'):\n",
    "    \"\"\"\n",
    "    Sovrappone una heatmap su un'immagine originale con un parametro alpha regolabile.\n",
    "    \n",
    "    Args:\n",
    "        original (numpy.ndarray): Immagine originale in formato RGB e normalizzata tra 0 e 1.\n",
    "        heatmap (numpy.ndarray): Heatmap normalizzata tra 0 e 1.\n",
    "        alpha (float): Trasparenza della heatmap.\n",
    "        colormap (str): Colormap da utilizzare per la heatmap.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Immagine con la heatmap sovrapposta.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB) / 255.0  # Converti da BGR a RGB e normalizza\n",
    "    overlay = (1 - alpha) * original + alpha * heatmap_color\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    return overlay\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Generare e Visualizzare Grad-CAM\n",
    "# -------------------------\n",
    "\n",
    "def generate_gradcam_plots(sample_index, gradcam_dir):\n",
    "    \"\"\"\n",
    "    Genera e salva le heatmap Grad-CAM per un campione specifico.\n",
    "    \n",
    "    Args:\n",
    "        sample_index (int): L'indice del campione da analizzare.\n",
    "        gradcam_dir (str): Directory dove salvare le immagini Grad-CAM.\n",
    "    \"\"\"\n",
    "    # Verifica che l'indice sia valido\n",
    "    if sample_index < 0 or sample_index >= len(test_dataset):\n",
    "        raise IndexError(f\"Indice {sample_index} fuori dal range del dataset.\")\n",
    "    \n",
    "    # Estrai il campione specifico\n",
    "    sample_data, sample_target = get_sample_by_index(test_dataset, sample_index)\n",
    "    sample_data = sample_data.to(device)\n",
    "    sample_target = sample_target.item()\n",
    "    \n",
    "    # Definisci il target layer\n",
    "    target_layer = model.conv2\n",
    "    \n",
    "    # Inizializza GradCAM senza use_cuda\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    \n",
    "    # Genera la heatmap Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=sample_data, targets=None)  # None = classe predetta\n",
    "    grayscale_cam = grayscale_cam[0]  # Rimuovi dimensione batch\n",
    "    \n",
    "    # Normalizza la heatmap tra 0 e 1\n",
    "    grayscale_cam_normalized = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-8)\n",
    "    \n",
    "    # Ottieni la classe predetta\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_data)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Denormalizza l'immagine originale per visualizzazione\n",
    "    original_image = denormalize(sample_data.cpu().clone(), [mean], [std]).squeeze().numpy()\n",
    "    \n",
    "    # Flip orizzontale e rotazione di 90 gradi anti-clockwise\n",
    "    original_image = np.fliplr(original_image)  # Flip orizzontale\n",
    "    original_image = np.rot90(original_image, k=1)  # Rotazione di 90 gradi anti-clockwise\n",
    "    \n",
    "    grayscale_cam_normalized = np.fliplr(grayscale_cam_normalized)  # Flip orizzontale della heatmap\n",
    "    grayscale_cam_normalized = np.rot90(grayscale_cam_normalized, k=1)  # Rotazione di 90 gradi anti-clockwise della heatmap\n",
    "    \n",
    "    # Converti l'immagine originale in RGB e normalizzala tra 0 e 1\n",
    "    original_image_rgb = np.stack([original_image]*3, axis=2)  # [H, W, 3]\n",
    "    original_image_rgb = original_image_rgb / 255.0  # Assicurati che l'immagine sia tra 0 e 1\n",
    "    \n",
    "    # Sovrapponi manualmente la heatmap con un alpha maggiore\n",
    "    visualization = overlay_heatmap_on_image(original_image_rgb, grayscale_cam_normalized, alpha=0.6)\n",
    "    \n",
    "    # Salva separatamente le quattro tipologie di immagini\n",
    "    \n",
    "    # 1. Immagine Originale\n",
    "    original_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_original.png')\n",
    "    plt.imsave(original_save_path, original_image, cmap='gray')\n",
    "    \n",
    "    # 2. Heatmap Grad-CAM\n",
    "    heatmap_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_heatmap.png')\n",
    "    plt.imsave(heatmap_save_path, grayscale_cam_normalized, cmap='jet')\n",
    "    \n",
    "    # 3. Immagine con Heatmap Sovrapposta\n",
    "    overlay_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_overlay.png')\n",
    "    plt.imsave(overlay_save_path, visualization)\n",
    "    \n",
    "    # 4. Grafico Completo\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    \n",
    "    # Plot 1: Immagine Originale\n",
    "    axs[0].imshow(original_image, cmap='gray')\n",
    "    axs[0].set_title(f\"Immagine Originale - Classe Vera: {class_mapping[sample_target]}\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot 2: Heatmap Grad-CAM\n",
    "    im = axs[1].imshow(grayscale_cam_normalized, cmap='jet')\n",
    "    axs[1].set_title(\"Heatmap Grad-CAM\")\n",
    "    axs[1].axis('off')\n",
    "    # Aggiungi una barra laterale (colorbar)\n",
    "    cbar = fig.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel('Intensità', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Plot 3: Immagine con Heatmap Sovrapposta\n",
    "    axs[2].imshow(visualization)\n",
    "    axs[2].set_title(f\"Classe Predetta: {class_mapping[pred_class]}\")\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    # Salva il grafico completo\n",
    "    chart_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_chart.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(chart_save_path)\n",
    "    plt.close(fig)  # Chiudi la figura per liberare memoria\n",
    "    \n",
    "    print(f\"Immagine Originale salvata in: {original_save_path}\")\n",
    "    print(f\"Heatmap Grad-CAM salvata in: {heatmap_save_path}\")\n",
    "    print(f\"Immagine con Heatmap Sovrapposta salvata in: {overlay_save_path}\")\n",
    "    print(f\"Grafico Completo salvato in: {chart_save_path}\")\n",
    "    \n",
    "    # Pulisci i hook dopo aver finito\n",
    "    cam = None  # Libera risorse (GradCAM chiama automaticamente remove hooks nel suo metodo __del__)\n",
    "\n",
    "# -------------------------\n",
    "# Funzione Principale\n",
    "# -------------------------\n",
    "\n",
    "def main():\n",
    "    global model, test_dataset, class_mapping, mean, std, base_dir, device\n",
    "\n",
    "    # Impostazioni\n",
    "    learning_rate = 0.01\n",
    "    optimizer_type = \"SGD\"\n",
    "    grid_size = 5\n",
    "    spline_order = 3\n",
    "    norm_type = \"L2\"\n",
    "    num_of_classes = 62\n",
    "    batch_size = 1  # Rimuovere il batching\n",
    "\n",
    "    seed = 12\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "    mean, std = 0.1307, 0.3081\n",
    "\n",
    "    data_dir = '/home/magliolo/.cache/emnist/gzip/'\n",
    "\n",
    "    base_dir = os.path.join(\n",
    "        'results',\n",
    "        f\"results_{norm_type}_{optimizer_type}_lr{learning_rate}_{grid_size}_{spline_order}\",\n",
    "        'KaNet5'\n",
    "    )\n",
    "    model_dir = os.path.join(base_dir, \"model\")\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Directory del modello non trovata: {model_dir}\")\n",
    "\n",
    "    # Utilizzo del modello KAN invece del classico LeNet5\n",
    "    model = LeNet5_KAN(num_classes=num_of_classes).to(device)\n",
    "\n",
    "    checkpoints = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError(f\"Nessun checkpoint trovato nella directory: {model_dir}\")\n",
    "    try:\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    except ValueError:\n",
    "        # Se il formato del checkpoint è diverso, usa semplicemente il file più recente\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: os.path.getctime(os.path.join(model_dir, x)))\n",
    "    checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Checkpoint caricato: {checkpoint_path}, Epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "    model.eval()\n",
    "\n",
    "    # Leggi i dati di test\n",
    "    test_images_path = os.path.join(data_dir, 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    test_labels_path = os.path.join(data_dir, 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    print(\"Leggendo i dati di test...\")\n",
    "    images_test = read_idx_images(test_images_path)\n",
    "    labels_test = read_idx_labels(test_labels_path)\n",
    "\n",
    "    # Converti in Tensori e normalizza\n",
    "    test_images_tensor = torch.from_numpy(images_test.copy()).unsqueeze(1).float()\n",
    "    test_labels_tensor = torch.from_numpy(labels_test.copy()).long()\n",
    "\n",
    "    # Normalizzazione\n",
    "    test_images_tensor = (test_images_tensor - mean) / std\n",
    "\n",
    "    # Sposta su GPU\n",
    "    test_images_tensor = test_images_tensor.to(device)\n",
    "    test_labels_tensor = test_labels_tensor.to(device)\n",
    "\n",
    "    # Crea il dataset in memoria\n",
    "    test_dataset = EMNISTMemoryDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "    # Crea il DataLoader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Test size: {len(test_loader.dataset)}\")\n",
    "    print(f\"Numero di classi uniche nel dataset di test: {len(set(labels_test))}\")\n",
    "    print(f\"Etichette uniche nel dataset di test: {sorted(set(labels_test))}\")\n",
    "\n",
    "    # Mappatura delle classi\n",
    "    class_mapping = get_emnist_class_mapping()\n",
    "\n",
    "    # Crea la subfolder \"GradCAM\" all'interno di base_dir\n",
    "    gradcam_dir = os.path.join(base_dir, \"GradCAM\")\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    print(f\"Directory per GradCAM: {gradcam_dir}\")\n",
    "\n",
    "    # Indici di esempio\n",
    "    sample_indices = selected_indices # Puoi aggiungere altri indici qui\n",
    "\n",
    "    for sample_index in sample_indices:\n",
    "        print(f\"\\nGenerando Grad-CAM per l'indice: {sample_index}\")\n",
    "        try:\n",
    "            generate_gradcam_plots(sample_index, gradcam_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nella generazione della heatmap per l'indice {sample_index}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb0c37b-9ad0-4fa1-895c-3b606db7ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Checkpoint caricato: results/results_None_SGD_lr0.01_5_3/KaNet5/model/checkpoint_epoch_50.pth, Epoch: 50\n",
      "Leggendo i dati di test...\n",
      "Test size: 116323\n",
      "Numero di classi uniche nel dataset di test: 62\n",
      "Etichette uniche nel dataset di test: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "Directory per GradCAM: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM\n",
      "\n",
      "Generando Grad-CAM per l'indice: 0\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_0_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 1\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_1_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 2\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_2_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 49\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_49_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 52\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_52_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 65\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_65_chart.png\n",
      "\n",
      "Generando Grad-CAM per l'indice: 100\n",
      "Immagine Originale salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_original.png\n",
      "Heatmap Grad-CAM salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_heatmap.png\n",
      "Immagine con Heatmap Sovrapposta salvata in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_overlay.png\n",
      "Grafico Completo salvato in: results/results_None_SGD_lr0.01_5_3/KaNet5/GradCAM/sample_100_chart.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import struct\n",
    "import random\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Modello KAN\n",
    "# -------------------------\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "import kan_convolutional.convolution\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "\n",
    "class LeNet5_KAN(nn.Module):\n",
    "    def __init__(self, num_classes=62):  # EMNIST Balanced ha 62 classi\n",
    "        super(LeNet5_KAN, self).__init__()\n",
    "        \n",
    "        # Primo strato conv: input=1 canale, output=6 filtri, kernel=5x5\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=(5,5),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            dilation=(1,1),\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.ReLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=(-1, 1)\n",
    "        )\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Secondo strato conv: input=6 canali, output=16 filtri, kernel=5x5\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=(5,5),\n",
    "            stride=(1,1),\n",
    "            padding=(0,0),\n",
    "            dilation=(1,1),\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.1,\n",
    "            scale_base=1.0,\n",
    "            scale_spline=1.0,\n",
    "            base_activation=torch.nn.ReLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=(-1, 1)\n",
    "        )\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Dopo conv1+pool1 (28x28 -> conv5x5->24x24 -> pool->12x12)\n",
    "        # Dopo conv2+pool2 (12x12 -> conv5x5->8x8 -> pool->4x4)\n",
    "        # 16 canali da 4x4 => 16*4*4=256\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passo 1: conv + pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Passo 2: conv + pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers con ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output Layer (senza attivazione)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# Definizione del Dataset in Memoria\n",
    "# -------------------------\n",
    "\n",
    "class EMNISTMemoryDataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor):\n",
    "        self.data = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# -------------------------\n",
    "# Funzioni per leggere i file IDX\n",
    "# -------------------------\n",
    "\n",
    "def read_idx_images(file_path):\n",
    "    \"\"\"Legge immagini in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_idx_labels(file_path):\n",
    "    \"\"\"Legge etichette in formato IDX.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# -------------------------\n",
    "# Funzione di Denormalizzazione\n",
    "# -------------------------\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "# -------------------------\n",
    "# Mappatura delle Classi\n",
    "# -------------------------\n",
    "\n",
    "def get_emnist_class_mapping():\n",
    "    characters = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    return {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Estrarre un Campione Specifico\n",
    "# -------------------------\n",
    "\n",
    "def get_sample_by_index(dataset, index):\n",
    "    if index < 0 or index >= len(dataset):\n",
    "        raise IndexError(\"Indice fuori dal range del dataset.\")\n",
    "    sample_data, sample_target = dataset[index]\n",
    "    return sample_data.unsqueeze(0), sample_target  # Aggiungi dimensione batch\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Sovrapporre la Heatmap con un Alpha Regolabile\n",
    "# -------------------------\n",
    "\n",
    "def overlay_heatmap_on_image(original, heatmap, alpha=0.6, colormap='jet'):\n",
    "    \"\"\"\n",
    "    Sovrappone una heatmap su un'immagine originale con un parametro alpha regolabile.\n",
    "    \n",
    "    Args:\n",
    "        original (numpy.ndarray): Immagine originale in formato RGB e normalizzata tra 0 e 1.\n",
    "        heatmap (numpy.ndarray): Heatmap normalizzata tra 0 e 1.\n",
    "        alpha (float): Trasparenza della heatmap.\n",
    "        colormap (str): Colormap da utilizzare per la heatmap.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Immagine con la heatmap sovrapposta.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB) / 255.0  # Converti da BGR a RGB e normalizza\n",
    "    overlay = (1 - alpha) * original + alpha * heatmap_color\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    return overlay\n",
    "\n",
    "# -------------------------\n",
    "# Funzione per Generare e Visualizzare Grad-CAM\n",
    "# -------------------------\n",
    "\n",
    "def generate_gradcam_plots(sample_index, gradcam_dir):\n",
    "    \"\"\"\n",
    "    Genera e salva le heatmap Grad-CAM per un campione specifico.\n",
    "    \n",
    "    Args:\n",
    "        sample_index (int): L'indice del campione da analizzare.\n",
    "        gradcam_dir (str): Directory dove salvare le immagini Grad-CAM.\n",
    "    \"\"\"\n",
    "    # Verifica che l'indice sia valido\n",
    "    if sample_index < 0 or sample_index >= len(test_dataset):\n",
    "        raise IndexError(f\"Indice {sample_index} fuori dal range del dataset.\")\n",
    "    \n",
    "    # Estrai il campione specifico\n",
    "    sample_data, sample_target = get_sample_by_index(test_dataset, sample_index)\n",
    "    sample_data = sample_data.to(device)\n",
    "    sample_target = sample_target.item()\n",
    "    \n",
    "    # Definisci il target layer\n",
    "    target_layer = model.conv2\n",
    "    \n",
    "    # Inizializza GradCAM senza use_cuda\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    \n",
    "    # Genera la heatmap Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=sample_data, targets=None)  # None = classe predetta\n",
    "    grayscale_cam = grayscale_cam[0]  # Rimuovi dimensione batch\n",
    "    \n",
    "    # Normalizza la heatmap tra 0 e 1\n",
    "    grayscale_cam_normalized = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-8)\n",
    "    \n",
    "    # Ottieni la classe predetta\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_data)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Denormalizza l'immagine originale per visualizzazione\n",
    "    original_image = denormalize(sample_data.cpu().clone(), [mean], [std]).squeeze().numpy()\n",
    "    \n",
    "    # Flip orizzontale e rotazione di 90 gradi anti-clockwise\n",
    "    original_image = np.fliplr(original_image)  # Flip orizzontale\n",
    "    original_image = np.rot90(original_image, k=1)  # Rotazione di 90 gradi anti-clockwise\n",
    "    \n",
    "    grayscale_cam_normalized = np.fliplr(grayscale_cam_normalized)  # Flip orizzontale della heatmap\n",
    "    grayscale_cam_normalized = np.rot90(grayscale_cam_normalized, k=1)  # Rotazione di 90 gradi anti-clockwise della heatmap\n",
    "    \n",
    "    # Converti l'immagine originale in RGB e normalizzala tra 0 e 1\n",
    "    original_image_rgb = np.stack([original_image]*3, axis=2)  # [H, W, 3]\n",
    "    original_image_rgb = original_image_rgb / 255.0  # Assicurati che l'immagine sia tra 0 e 1\n",
    "    \n",
    "    # Sovrapponi manualmente la heatmap con un alpha maggiore\n",
    "    visualization = overlay_heatmap_on_image(original_image_rgb, grayscale_cam_normalized, alpha=0.6)\n",
    "    \n",
    "    # Salva separatamente le quattro tipologie di immagini\n",
    "    \n",
    "    # 1. Immagine Originale\n",
    "    original_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_original.png')\n",
    "    plt.imsave(original_save_path, original_image, cmap='gray')\n",
    "    \n",
    "    # 2. Heatmap Grad-CAM\n",
    "    heatmap_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_heatmap.png')\n",
    "    plt.imsave(heatmap_save_path, grayscale_cam_normalized, cmap='jet')\n",
    "    \n",
    "    # 3. Immagine con Heatmap Sovrapposta\n",
    "    overlay_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_overlay.png')\n",
    "    plt.imsave(overlay_save_path, visualization)\n",
    "    \n",
    "    # 4. Grafico Completo\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    \n",
    "    # Plot 1: Immagine Originale\n",
    "    axs[0].imshow(original_image, cmap='gray')\n",
    "    axs[0].set_title(f\"Immagine Originale - Classe Vera: {class_mapping[sample_target]}\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot 2: Heatmap Grad-CAM\n",
    "    im = axs[1].imshow(grayscale_cam_normalized, cmap='jet')\n",
    "    axs[1].set_title(\"Heatmap Grad-CAM\")\n",
    "    axs[1].axis('off')\n",
    "    # Aggiungi una barra laterale (colorbar)\n",
    "    cbar = fig.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel('Intensità', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Plot 3: Immagine con Heatmap Sovrapposta\n",
    "    axs[2].imshow(visualization)\n",
    "    axs[2].set_title(f\"Classe Predetta: {class_mapping[pred_class]}\")\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    # Salva il grafico completo\n",
    "    chart_save_path = os.path.join(gradcam_dir, f'sample_{sample_index}_chart.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(chart_save_path)\n",
    "    plt.close(fig)  # Chiudi la figura per liberare memoria\n",
    "    \n",
    "    print(f\"Immagine Originale salvata in: {original_save_path}\")\n",
    "    print(f\"Heatmap Grad-CAM salvata in: {heatmap_save_path}\")\n",
    "    print(f\"Immagine con Heatmap Sovrapposta salvata in: {overlay_save_path}\")\n",
    "    print(f\"Grafico Completo salvato in: {chart_save_path}\")\n",
    "    \n",
    "    # Pulisci i hook dopo aver finito\n",
    "    cam = None  # Libera risorse (GradCAM chiama automaticamente remove hooks nel suo metodo __del__)\n",
    "\n",
    "# -------------------------\n",
    "# Funzione Principale\n",
    "# -------------------------\n",
    "\n",
    "def main():\n",
    "    global model, test_dataset, class_mapping, mean, std, base_dir, device\n",
    "\n",
    "    # Impostazioni\n",
    "    learning_rate = 0.01\n",
    "    optimizer_type = \"SGD\"\n",
    "    grid_size = 5\n",
    "    spline_order = 3\n",
    "    norm_type = \"None\"\n",
    "    num_of_classes = 62\n",
    "    batch_size = 1  # Rimuovere il batching\n",
    "\n",
    "    seed = 12\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "    mean, std = 0.1307, 0.3081\n",
    "\n",
    "    data_dir = '/home/magliolo/.cache/emnist/gzip/'\n",
    "\n",
    "    base_dir = os.path.join(\n",
    "        'results',\n",
    "        f\"results_{norm_type}_{optimizer_type}_lr{learning_rate}_{grid_size}_{spline_order}\",\n",
    "        'KaNet5'\n",
    "    )\n",
    "    model_dir = os.path.join(base_dir, \"model\")\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Directory del modello non trovata: {model_dir}\")\n",
    "\n",
    "    # Utilizzo del modello KAN invece del classico LeNet5\n",
    "    model = LeNet5_KAN(num_classes=num_of_classes).to(device)\n",
    "\n",
    "    checkpoints = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError(f\"Nessun checkpoint trovato nella directory: {model_dir}\")\n",
    "    try:\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    except ValueError:\n",
    "        # Se il formato del checkpoint è diverso, usa semplicemente il file più recente\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: os.path.getctime(os.path.join(model_dir, x)))\n",
    "    checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Checkpoint caricato: {checkpoint_path}, Epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "    model.eval()\n",
    "\n",
    "    # Leggi i dati di test\n",
    "    test_images_path = os.path.join(data_dir, 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    test_labels_path = os.path.join(data_dir, 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    print(\"Leggendo i dati di test...\")\n",
    "    images_test = read_idx_images(test_images_path)\n",
    "    labels_test = read_idx_labels(test_labels_path)\n",
    "\n",
    "    # Converti in Tensori e normalizza\n",
    "    test_images_tensor = torch.from_numpy(images_test.copy()).unsqueeze(1).float()\n",
    "    test_labels_tensor = torch.from_numpy(labels_test.copy()).long()\n",
    "\n",
    "    # Normalizzazione\n",
    "    test_images_tensor = (test_images_tensor - mean) / std\n",
    "\n",
    "    # Sposta su GPU\n",
    "    test_images_tensor = test_images_tensor.to(device)\n",
    "    test_labels_tensor = test_labels_tensor.to(device)\n",
    "\n",
    "    # Crea il dataset in memoria\n",
    "    test_dataset = EMNISTMemoryDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "    # Crea il DataLoader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Test size: {len(test_loader.dataset)}\")\n",
    "    print(f\"Numero di classi uniche nel dataset di test: {len(set(labels_test))}\")\n",
    "    print(f\"Etichette uniche nel dataset di test: {sorted(set(labels_test))}\")\n",
    "\n",
    "    # Mappatura delle classi\n",
    "    class_mapping = get_emnist_class_mapping()\n",
    "\n",
    "    # Crea la subfolder \"GradCAM\" all'interno di base_dir\n",
    "    gradcam_dir = os.path.join(base_dir, \"GradCAM\")\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    print(f\"Directory per GradCAM: {gradcam_dir}\")\n",
    "\n",
    "    # Indici di esempio\n",
    "    sample_indices = selected_indices  # Puoi aggiungere altri indici qui\n",
    "\n",
    "    for sample_index in sample_indices:\n",
    "        print(f\"\\nGenerando Grad-CAM per l'indice: {sample_index}\")\n",
    "        try:\n",
    "            generate_gradcam_plots(sample_index, gradcam_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nella generazione della heatmap per l'indice {sample_index}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
