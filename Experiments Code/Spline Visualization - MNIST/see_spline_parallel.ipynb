{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fb99c3-6291-4b87-b5e1-65b12ecdf969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di parametri KAN: 2662000\n",
      "Numero di parametri MLP: 266610\n",
      "Differenza (KAN - MLP): 2395390\n",
      "Rapporto (KAN / MLP): 9.98\n"
     ]
    }
   ],
   "source": [
    "def calculate_kan_parameters(layers_hidden, grid_size, spline_order, enable_scaler=False):\n",
    "    \"\"\"\n",
    "    Calcola il numero totale di parametri per una rete KAN fully connected.\n",
    "\n",
    "    Args:\n",
    "        layers_hidden (list): Numero di neuroni per ciascun layer, inclusi input e output.\n",
    "        grid_size (int): Dimensione della griglia della spline.\n",
    "        spline_order (int): Ordine della spline.\n",
    "        enable_scaler (bool): Se True, considera anche i parametri scaler.\n",
    "\n",
    "    Returns:\n",
    "        int: Numero totale di parametri.\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
    "        base_params = in_features * out_features\n",
    "        spline_params = in_features * out_features * (grid_size + spline_order)\n",
    "        scaler_params = in_features * out_features if enable_scaler else 0\n",
    "        total_params += base_params + spline_params + scaler_params\n",
    "    return total_params\n",
    "\n",
    "\n",
    "def calculate_mlp_parameters(layers_hidden):\n",
    "    \"\"\"\n",
    "    Calcola il numero totale di parametri per una rete fully connected standard (MLP).\n",
    "\n",
    "    Args:\n",
    "        layers_hidden (list): Numero di neuroni per ciascun layer, inclusi input e output.\n",
    "\n",
    "    Returns:\n",
    "        int: Numero totale di parametri.\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
    "        base_params = in_features * out_features\n",
    "        bias_params = out_features  # Bias per ogni neurone di output\n",
    "        total_params += base_params + bias_params\n",
    "    return total_params\n",
    "\n",
    "\n",
    "def compare_kan_mlp(layers_hidden, grid_size, spline_order, enable_scaler=False):\n",
    "    \"\"\"\n",
    "    Confronta il numero di parametri tra una rete KAN e una MLP.\n",
    "\n",
    "    Args:\n",
    "        layers_hidden (list): Numero di neuroni per ciascun layer, inclusi input e output.\n",
    "        grid_size (int): Dimensione della griglia per le spline.\n",
    "        spline_order (int): Ordine delle spline.\n",
    "        enable_scaler (bool): Se True, considera i parametri scaler nelle KAN.\n",
    "\n",
    "    Returns:\n",
    "        None: Stampa i risultati.\n",
    "    \"\"\"\n",
    "    kan_params = calculate_kan_parameters(layers_hidden, grid_size, spline_order, enable_scaler)\n",
    "    mlp_params = calculate_mlp_parameters(layers_hidden)\n",
    "    difference = kan_params - mlp_params\n",
    "    ratio = kan_params / mlp_params if mlp_params > 0 else float('inf')\n",
    "\n",
    "    print(f\"Numero di parametri KAN: {kan_params}\")\n",
    "    print(f\"Numero di parametri MLP: {mlp_params}\")\n",
    "    print(f\"Differenza (KAN - MLP): {difference}\")\n",
    "    print(f\"Rapporto (KAN / MLP): {ratio:.2f}\")\n",
    "\n",
    "# Esempio\n",
    "layers_hidden = [784, 300, 100, 10]  # Struttura della rete\n",
    "grid_size = 5  # Dimensione della griglia\n",
    "spline_order = 3  # Ordine delle spline\n",
    "enable_scaler = True  # Considera i parametri scaler opzionali\n",
    "\n",
    "compare_kan_mlp(layers_hidden, grid_size, spline_order, enable_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0160ecb-fc4e-432d-9bee-025528b6d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_28x28.KANLinearFullyConnected import KANLinearFullyConnected \n",
    "import os\n",
    "import inspect\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from scipy.interpolate import BSpline\n",
    "import re\n",
    "import imageio.v2 as imageio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from scipy.interpolate import BSpline, LSQUnivariateSpline, UnivariateSpline\n",
    "\n",
    "\n",
    "def load_model(model_path, model_class, model_args):\n",
    "    \"\"\"\n",
    "    Carica un modello KAN salvato come checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Percorso del file salvato.\n",
    "        model_class: Classe del modello.\n",
    "        model_args (dict): Argomenti per istanziare il modello.\n",
    "    \n",
    "    Returns:\n",
    "        torch.nn.Module: Modello ricostruito con i pesi caricati.\n",
    "    \"\"\"\n",
    "    # Ricrea il modello utilizzando la classe e gli argomenti\n",
    "    model = model_class(**model_args)\n",
    "    \n",
    "    # Carica il checkpoint e accedi al model_state_dict\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # Imposta in modalità di valutazione\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def load_models_from_folder(model_folder, model_class, model_args, max_workers=4):\n",
    "    \"\"\"\n",
    "    Carica modelli KAN da una cartella specificata in parallelo e restituisce un array di modelli.\n",
    "\n",
    "    Args:\n",
    "        model_folder (str): Percorso della cartella contenente i checkpoint.\n",
    "        model_class: Classe del modello.\n",
    "        model_args (dict): Argomenti per istanziare il modello.\n",
    "        max_workers (int): Numero massimo di thread paralleli (default: 4).\n",
    "\n",
    "    Returns:\n",
    "        list: Lista di modelli caricati.\n",
    "    \"\"\"\n",
    "    # Trova i checkpoint disponibili\n",
    "    checkpoint_files = [\n",
    "        f for f in os.listdir(model_folder) if re.match(r'checkpoint_epoch_(\\d+)\\.pth', f)\n",
    "    ]\n",
    "\n",
    "    # Estrarre i numeri di epoch dai nomi dei file\n",
    "    epoch_numbers = sorted(\n",
    "        int(re.match(r'checkpoint_epoch_(\\d+)\\.pth', f).group(1)) for f in checkpoint_files\n",
    "    )\n",
    "\n",
    "    if not epoch_numbers:\n",
    "        raise ValueError(\"Nessun checkpoint trovato nella cartella specificata.\")\n",
    "\n",
    "    print(f\"Checkpoint trovati: da epoch {min(epoch_numbers)} a epoch {max(epoch_numbers)}\")\n",
    "\n",
    "    # Funzione per caricare un modello dato il suo epoch\n",
    "    def load_model_for_epoch(epoch):\n",
    "        model_path = os.path.join(model_folder, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "        return load_model(model_path, model_class, model_args)\n",
    "\n",
    "    # Caricare i modelli in parallelo\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        models = list(executor.map(load_model_for_epoch, epoch_numbers))\n",
    "\n",
    "    print(f\"Numero di modelli caricati: {len(models)}\")\n",
    "    return models\n",
    "\n",
    "    \n",
    "def compute_spline(x, grid, weights, order):\n",
    "    \"\"\"\n",
    "    Computes the value of the B-spline at given points x.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray): Points where to evaluate the spline.\n",
    "        grid (numpy.ndarray): Knot vector.\n",
    "        weights (numpy.ndarray): Spline coefficients.\n",
    "        order (int): Order of the spline.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Evaluated spline values at points x, augmented knots, degree)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = x.squeeze(-1).numpy()\n",
    "        knots = grid\n",
    "        degree = order\n",
    "\n",
    "        # Ensure that the number of knots is equal to len(weights) + degree + 1\n",
    "        n_knots_needed = len(weights) + degree + 1\n",
    "        if len(knots) < n_knots_needed:\n",
    "            # Augment knots by repeating the first and last knots as needed\n",
    "            knots = np.concatenate((\n",
    "                np.full(degree, knots[0]),\n",
    "                knots,\n",
    "                np.full(degree, knots[-1])\n",
    "            ))\n",
    "        spline = BSpline(knots, weights, degree)\n",
    "        y = spline(x)\n",
    "        return y, knots, degree\n",
    "    except Exception as e:\n",
    "        #print(f\"ERROR in compute_spline: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def plot_spline_for_neuron(model, layer_idx, in_neuron_idx, out_neuron_idx, grid_range=(-1, 1)):\n",
    "    \"\"\"\n",
    "    Generates plots of the learned splines with their control points, including debug statements.\n",
    "\n",
    "    Args:\n",
    "        model: Loaded KAN model.\n",
    "        layer_idx: Index of the selected layer.\n",
    "        in_neuron_idx: Index of the neuron in the previous layer.\n",
    "        out_neuron_idx: Index of the neuron in the current layer.\n",
    "        grid_range: Range of the grid for the splines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Select the layer\n",
    "        layer = model.layers[layer_idx]  \n",
    "        \n",
    "        # Extract the grid and weights\n",
    "        grid = layer.grid[in_neuron_idx].detach().cpu().numpy()  # Grid of the spline\n",
    "        spline_weights = layer.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()  # Spline weights\n",
    "        \n",
    "        # Generate x points for the extended spline\n",
    "        x_extended = torch.linspace(grid_range[0], grid_range[1], 500).unsqueeze(1)\n",
    "\n",
    "        \n",
    "        # Compute the spline and get knots and degree\n",
    "        y_extended, knots, degree = compute_spline(x_extended, grid, spline_weights, layer.spline_order)\n",
    "\n",
    "\n",
    "        # Compute Greville abscissae\n",
    "        greville_abscissae = np.array([\n",
    "            np.sum(knots[i+1:i+degree+1]) / degree for i in range(len(spline_weights))\n",
    "        ])\n",
    "\n",
    "        # Generate the plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(x_extended.numpy().flatten(), y_extended, label=\"Spline\")\n",
    "        plt.scatter(greville_abscissae, spline_weights, color=\"red\", zorder=5, label=\"Control Points\")\n",
    "        plt.axvline(grid_range[0], color='r', linestyle='--', label=\"Grid Limits\")\n",
    "        plt.axvline(grid_range[1], color='r', linestyle='--')\n",
    "        plt.title(f\"Spline for Layer {layer_idx}, Neuron {in_neuron_idx} -> Neuron {out_neuron_idx}\")\n",
    "        plt.xlabel(\"Input\")\n",
    "        plt.ylabel(\"Spline Output\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in plot_spline_for_neuron: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def calculate_ylim(models, layer_idx, in_neuron_idx, out_neuron_idx, grid_range=(-1, 1)):\n",
    "    \"\"\"\n",
    "    Calculate the y-axis limits based on the lowest and highest spline values across all models.\n",
    "\n",
    "    Args:\n",
    "        models: List of KAN models.\n",
    "        layer_idx: Index of the selected layer.\n",
    "        in_neuron_idx: Index of the neuron in the previous layer.\n",
    "        out_neuron_idx: Index of the neuron in the current layer.\n",
    "        grid_range: Range of the grid for the splines.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (min_y, max_y) representing the y-axis limits.\n",
    "    \"\"\"\n",
    "    min_y = float('inf')  # Initialize to a very large value\n",
    "    max_y = float('-inf') # Initialize to a very small value\n",
    "\n",
    "    x_extended = torch.linspace(grid_range[0], grid_range[1], 500).unsqueeze(1)\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            # Select the layer\n",
    "            layer = model.layers[layer_idx]\n",
    "\n",
    "            # Extract grid and weights\n",
    "            grid = layer.grid[in_neuron_idx].detach().cpu().numpy()\n",
    "            spline_weights = layer.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()\n",
    "\n",
    "            # Compute the spline values\n",
    "            y_extended, _, _ = compute_spline(x_extended, grid, spline_weights, layer.spline_order)\n",
    "\n",
    "            # Update global min and max\n",
    "            min_y = min(min_y, y_extended.min())\n",
    "            max_y = max(max_y, y_extended.max())\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in calculate_ylim for model: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return min_y, max_y\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def collect_all_neuron_statistics(models, padding_value=0.0):\n",
    "    \"\"\"\n",
    "    Collects per-neuron statistics for all neurons across all models at once,\n",
    "    returning a 3D tensor suitable for GPU computations.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of models (PyTorch models).\n",
    "        padding_value (float): The value used for padding.\n",
    "\n",
    "    Returns:\n",
    "        tensor_data (torch.Tensor): A 3D tensor of shape [N_max, L, N_models].\n",
    "        mask (torch.Tensor): A 3D mask tensor indicating valid entries (1) and padded entries (0).\n",
    "    \"\"\"\n",
    "    N_models = len(models)\n",
    "    L = len(models[0].layers)  # Assuming all models have the same number of layers\n",
    "\n",
    "    # Determine the maximum number of neurons in any layer\n",
    "    N_ls = []\n",
    "    for layer in models[0].layers:\n",
    "        N_l = layer.spline_weight.size(0)  # Number of output neurons in the layer\n",
    "        N_ls.append(N_l)\n",
    "    N_max = max(N_ls)  # Maximum number of neurons in any layer\n",
    "\n",
    "    # Initialize tensor_data and mask\n",
    "    tensor_data = torch.full((N_max, L, N_models), padding_value, dtype=torch.float32)\n",
    "    mask = torch.zeros((N_max, L, N_models), dtype=torch.float32)\n",
    "\n",
    "    # For each model\n",
    "    for model_idx, model in enumerate(models):\n",
    "        # For each layer\n",
    "        for layer_idx, layer in enumerate(model.layers):\n",
    "            N_l = N_ls[layer_idx]  # Number of neurons in this layer\n",
    "\n",
    "            # Collect per-neuron statistics (e.g., mean of spline weights)\n",
    "            neuron_stats = []\n",
    "            for neuron_idx in range(N_l):\n",
    "                # Get the spline weights for this neuron\n",
    "                neuron_weights = layer.spline_weight[neuron_idx]  # Shape: [num_in_neurons, spline_weight_size]\n",
    "                neuron_weights = neuron_weights.flatten()\n",
    "                neuron_mean = neuron_weights.mean().item()\n",
    "                neuron_stats.append(neuron_mean)\n",
    "\n",
    "            # Convert to tensor\n",
    "            neuron_stats_tensor = torch.tensor(neuron_stats, dtype=torch.float32)\n",
    "\n",
    "            # Place into tensor_data\n",
    "            tensor_data[:N_l, layer_idx, model_idx] = neuron_stats_tensor\n",
    "            mask[:N_l, layer_idx, model_idx] = 1  # Mark valid entries\n",
    "\n",
    "    return tensor_data, mask\n",
    "\n",
    "def compute_statistics_on_gpu(tensor_data, mask):\n",
    "    \"\"\"\n",
    "    Compute statistics over all neurons across all models using CUDA, handling padded values efficiently.\n",
    "\n",
    "    Args:\n",
    "        tensor_data (torch.Tensor): The data tensor of shape [N_max, L, N_models].\n",
    "        mask (torch.Tensor): The mask tensor of the same shape.\n",
    "\n",
    "    Returns:\n",
    "        stats (dict): A dictionary with computed statistics.\n",
    "    \"\"\"\n",
    "    # Move data to GPU\n",
    "    tensor_data = tensor_data.cuda()\n",
    "    mask = mask.cuda()\n",
    "\n",
    "    # Compute statistics using masked operations\n",
    "    # To prevent division by zero, ensure mask sum is at least 1\n",
    "    total_valid = mask.sum()\n",
    "    if total_valid == 0:\n",
    "        raise ValueError(\"No valid data found for statistics computation.\")\n",
    "\n",
    "    # Calculate mean\n",
    "    mean = (tensor_data * mask).sum() / total_valid\n",
    "\n",
    "    # Calculate variance\n",
    "    # First, compute the squared differences\n",
    "    squared_diff = ((tensor_data - mean) * mask) ** 2\n",
    "    variance = squared_diff.sum() / total_valid\n",
    "\n",
    "    # Compute min and max using masked operations\n",
    "    valid_data = tensor_data[mask == 1]\n",
    "    min_value = valid_data.min()\n",
    "    max_value = valid_data.max()\n",
    "    peak_to_peak = max_value - min_value\n",
    "    std_dev = torch.sqrt(variance)\n",
    "\n",
    "    stats = {\n",
    "        'mean': mean.item(),\n",
    "        'variance': variance.item(),\n",
    "        'min': min_value.item(),\n",
    "        'max': max_value.item(),\n",
    "        'peak_to_peak': peak_to_peak.item(),\n",
    "        'std_dev': std_dev.item(),\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "def compute_statistics_for_layer_and_model(tensor_data, mask, layer_idx, model_idx):\n",
    "    \"\"\"\n",
    "    Compute statistics for a specific layer and model.\n",
    "    \n",
    "    Args:\n",
    "        tensor_data (torch.Tensor): The data tensor of shape [N_max, L, N_models].\n",
    "        mask (torch.Tensor): The mask tensor of the same shape.\n",
    "        layer_idx (int): The index of the layer.\n",
    "        model_idx (int): The index of the model.\n",
    "        \n",
    "    Returns:\n",
    "        stats (dict): A dictionary with computed statistics.\n",
    "    \"\"\"\n",
    "    # Move data to GPU\n",
    "    tensor_data = tensor_data.cuda()\n",
    "    mask = mask.cuda()\n",
    "    \n",
    "    # Extract data for the specified layer and model\n",
    "    data_slice = tensor_data[:, layer_idx, model_idx]\n",
    "    mask_slice = mask[:, layer_idx, model_idx]\n",
    "    \n",
    "    # Extract valid data\n",
    "    valid_data = data_slice[mask_slice == 1]\n",
    "    total_valid = valid_data.numel()\n",
    "    if total_valid == 0:\n",
    "        raise ValueError(\"No valid data found for the specified layer and model.\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean = valid_data.mean()\n",
    "    variance = valid_data.var(unbiased=False)\n",
    "    min_value = valid_data.min()\n",
    "    max_value = valid_data.max()\n",
    "    peak_to_peak = max_value - min_value\n",
    "    std_dev = valid_data.std(unbiased=False)\n",
    "    \n",
    "    stats = {\n",
    "        'mean': mean.item(),\n",
    "        'variance': variance.item(),\n",
    "        'min': min_value.item(),\n",
    "        'max': max_value.item(),\n",
    "        'peak_to_peak': peak_to_peak.item(),\n",
    "        'std_dev': std_dev.item(),\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def compute_statistics_for_layer_across_models(tensor_data, mask, layer_idx):\n",
    "    \"\"\"\n",
    "    Compute statistics for a specific layer across all models.\n",
    "    \n",
    "    Args:\n",
    "        tensor_data (torch.Tensor): The data tensor of shape [N_max, L, N_models].\n",
    "        mask (torch.Tensor): The mask tensor of the same shape.\n",
    "        layer_idx (int): The index of the layer.\n",
    "        \n",
    "    Returns:\n",
    "        stats (dict): A dictionary with computed statistics.\n",
    "    \"\"\"\n",
    "    # Move data to GPU\n",
    "    tensor_data = tensor_data.cuda()\n",
    "    mask = mask.cuda()\n",
    "    \n",
    "    # Extract data for the specified layer across all models\n",
    "    data_slice = tensor_data[:, layer_idx, :]\n",
    "    mask_slice = mask[:, layer_idx, :]\n",
    "    \n",
    "    # Extract valid data\n",
    "    valid_data = data_slice[mask_slice == 1]\n",
    "    total_valid = valid_data.numel()\n",
    "    if total_valid == 0:\n",
    "        raise ValueError(\"No valid data found for the specified layer.\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean = valid_data.mean()\n",
    "    variance = valid_data.var(unbiased=False)\n",
    "    min_value = valid_data.min()\n",
    "    max_value = valid_data.max()\n",
    "    peak_to_peak = max_value - min_value\n",
    "    std_dev = valid_data.std(unbiased=False)\n",
    "    \n",
    "    stats = {\n",
    "        'mean': mean.item(),\n",
    "        'variance': variance.item(),\n",
    "        'min': min_value.item(),\n",
    "        'max': max_value.item(),\n",
    "        'peak_to_peak': peak_to_peak.item(),\n",
    "        'std_dev': std_dev.item(),\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def print_statistics_table(models, grid_range=(-1, 1)):\n",
    "    \"\"\"\n",
    "    Calcola e stampa una tabella contenente i valori delle statistiche per i modelli.\n",
    "\n",
    "    Args:\n",
    "        models: Lista di modelli KAN su cui calcolare le statistiche.\n",
    "        grid_range: Intervallo della griglia per calcolare i valori della spline.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcola le statistiche per ogni modello\n",
    "        models_statistics = collect_statistics_for_models(models, grid_range=(-1, 1))\n",
    "\n",
    "        if not models_statistics:\n",
    "            print(\"Nessuna statistica calcolata.\")\n",
    "            return\n",
    "\n",
    "        # Prepara i dati per la tabella\n",
    "        table_data = []\n",
    "        for idx, stats in enumerate(models_statistics, start=1):\n",
    "            row = {'Model': f\"Model {idx}\"}\n",
    "            row.update(stats)\n",
    "            table_data.append(row)\n",
    "\n",
    "        # Crea un DataFrame per visualizzare i dati\n",
    "        df = pd.DataFrame(table_data)\n",
    "\n",
    "        # Print the table in a clean format\n",
    "        print(\"\\nStatistiche per i modelli:\")\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in print_statistics_table: {str(e)}\")\n",
    "\n",
    "def compare_splines_for_neuron(\n",
    "    model1, model2, layer_idx, in_neuron_idx, out_neuron_idx, grid_range=(-1, 1), \n",
    "    plot_control_points=True, model_index1=1, model_index2=2, save_path=None, y_min = -0.0015 , y_max = 0.0015\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates plots of the learned splines for the same layer and neuron pair in two models.\n",
    "\n",
    "    Args:\n",
    "        model1: First KAN model.\n",
    "        model2: Second KAN model.\n",
    "        layer_idx: Index of the selected layer.\n",
    "        in_neuron_idx: Index of the neuron in the previous layer.\n",
    "        out_neuron_idx: Index of the neuron in the current layer.\n",
    "        grid_range: Range of the grid for the splines.\n",
    "        plot_control_points: If True, plots the control points (default: True).\n",
    "        model_index1: Index of the first model for labeling.\n",
    "        model_index2: Index of the second model for labeling.\n",
    "        save_path: If provided, saves the plot to the specified path (default: None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Select the layers\n",
    "        layer1 = model1.layers[layer_idx]\n",
    "        layer2 = model2.layers[layer_idx]\n",
    "        \n",
    "        # Extract the grids and weights for both models\n",
    "        grid1 = layer1.grid[in_neuron_idx].detach().cpu().numpy()\n",
    "        spline_weights1 = layer1.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()\n",
    "        \n",
    "        grid2 = layer2.grid[in_neuron_idx].detach().cpu().numpy()\n",
    "        spline_weights2 = layer2.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()\n",
    "        \n",
    "        # Generate x points for the extended spline\n",
    "        x_extended = torch.linspace(grid_range[0], grid_range[1], 500).unsqueeze(1)\n",
    "        \n",
    "        # Compute the splines and get knots and degrees for both models\n",
    "        y_extended1, knots1, degree1 = compute_spline(x_extended, grid1, spline_weights1, layer1.spline_order)\n",
    "        y_extended2, knots2, degree2 = compute_spline(x_extended, grid2, spline_weights2, layer2.spline_order)\n",
    "        \n",
    "        # Compute Greville abscissae for both models\n",
    "        greville_abscissae1 = np.array([\n",
    "            np.sum(knots1[i+1:i+degree1+1]) / degree1 for i in range(len(spline_weights1))\n",
    "        ])\n",
    "        greville_abscissae2 = np.array([\n",
    "            np.sum(knots2[i+1:i+degree2+1]) / degree2 for i in range(len(spline_weights2))\n",
    "        ])\n",
    "\n",
    "        # Generate the plot\n",
    "        plt.figure(figsize=(10, 6))  # Aumenta la dimensione del plot per spazio alla legenda\n",
    "        plt.plot(x_extended.numpy().flatten(), y_extended1, label=f\"Model {model_index1} - Spline\", color=\"blue\")\n",
    "        plt.plot(x_extended.numpy().flatten(), y_extended2, label=f\"Model {model_index2} - Spline\", color=\"green\")\n",
    "\n",
    "        # Plot control points only if the parameter is True\n",
    "        if plot_control_points:\n",
    "            plt.scatter(greville_abscissae1, spline_weights1, color=\"red\", zorder=5, label=f\"Model {model_index1} - Control Points\")\n",
    "            plt.scatter(greville_abscissae2, spline_weights2, color=\"orange\", zorder=5, label=f\"Model {model_index2} - Control Points\")\n",
    "        \n",
    "        # Set fixed axis limits\n",
    "        plt.xlim(grid_range[0] * 1.10, grid_range[1]*1.10)\n",
    "        plt.ylim(y_min, y_max)\n",
    "\n",
    "        # Add grid lines\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Position the legend outside the plot on the right\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")  # Sposta la legenda fuori dal grafico\n",
    "        \n",
    "        plt.title(f\"Spline Comparison for Layer {layer_idx}, Neuron {in_neuron_idx} -> Neuron {out_neuron_idx}\")\n",
    "        plt.xlabel(\"Input\")\n",
    "        plt.ylabel(\"Spline Output\")\n",
    "        plt.tight_layout()  # Adatta il layout per non tagliare la legenda\n",
    "\n",
    "        # Save or show the plot\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"Grafico salvato in: {save_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in compare_splines_for_neuron: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def find_max_spline_difference(model1, model2):\n",
    "    \"\"\"\n",
    "    Trova la coppia di neuroni (layer, neurone precedente, neurone successivo) \n",
    "    con la massima differenza tra i control point delle spline tra due modelli.\n",
    "\n",
    "    Args:\n",
    "        model1: Primo modello KAN caricato.\n",
    "        model2: Secondo modello KAN caricato.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (layer_idx, in_neuron_idx, out_neuron_idx, max_difference)\n",
    "    \"\"\"\n",
    "    max_difference = 0\n",
    "    max_indices = (-1, -1, -1)  # (layer_idx, in_neuron_idx, out_neuron_idx)\n",
    "\n",
    "    # Itera sui layer\n",
    "    for layer_idx, (layer1, layer2) in enumerate(zip(model1.layers, model2.layers)):\n",
    "        # Assumi che il numero di neuroni e spline sia identico nei due modelli\n",
    "        num_in_neurons = layer1.grid.size(0)\n",
    "        num_out_neurons = layer1.spline_weight.size(0)\n",
    "\n",
    "        # Itera sui neuroni in ingresso e uscita\n",
    "        for in_neuron_idx in range(num_in_neurons):\n",
    "            for out_neuron_idx in range(num_out_neurons):\n",
    "                # Estrai i control point (pesi) delle spline per entrambi i modelli\n",
    "                control_points1 = layer1.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()\n",
    "                control_points2 = layer2.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()\n",
    "\n",
    "                # Calcola la distanza tra i control point (norma L2)\n",
    "                difference = np.linalg.norm(control_points1 - control_points2)\n",
    "\n",
    "                # Aggiorna il massimo se necessario\n",
    "                if difference > max_difference:\n",
    "                    max_difference = difference\n",
    "                    max_indices = (layer_idx, in_neuron_idx, out_neuron_idx)\n",
    "\n",
    "    return max_indices + (max_difference,)\n",
    "\n",
    "def find_max_excursion(model, grid_range=(-1, 1)):\n",
    "    \"\"\"\n",
    "    Trova la tripla (layer_idx, in_neuron_idx, out_neuron_idx) nel modello che presenta\n",
    "    la massima escursione di valori (max - min) della spline.\n",
    "\n",
    "    Args:\n",
    "        model: Il modello KAN in cui cercare.\n",
    "        grid_range: Range della griglia per la spline.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (layer_idx, in_neuron_idx, out_neuron_idx, max_excursion)\n",
    "               con la massima escursione.\n",
    "    \"\"\"\n",
    "    max_excursion = float('-inf')  # Inizializza a un valore molto basso\n",
    "    max_indices = (-1, -1, -1)    # Placeholder per layer, neurone precedente, neurone successivo\n",
    "\n",
    "    x_extended = torch.linspace(grid_range[0], grid_range[1], 500).unsqueeze(1)\n",
    "\n",
    "    # Itera sui layer del modello\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        num_in_neurons = layer.grid.size(0)  # Numero di neuroni in ingresso\n",
    "        num_out_neurons = layer.spline_weight.size(0)  # Numero di neuroni in uscita\n",
    "\n",
    "        # Itera sui neuroni in ingresso e uscita\n",
    "        for in_neuron_idx in range(num_in_neurons):\n",
    "            for out_neuron_idx in range(num_out_neurons):\n",
    "                try:\n",
    "                    # Estrai griglia e pesi\n",
    "                    grid = layer.grid[in_neuron_idx].detach().cpu().numpy()\n",
    "                    spline_weights = layer.spline_weight[out_neuron_idx, in_neuron_idx].detach().cpu().numpy()\n",
    "\n",
    "                    # Calcola i valori della spline\n",
    "                    y_extended, _, _ = compute_spline(x_extended, grid, spline_weights, layer.spline_order)\n",
    "\n",
    "                    # Calcola l'escursione per questa connessione\n",
    "                    excursion = y_extended.max() - y_extended.min()\n",
    "\n",
    "                    # Aggiorna il massimo se necessario\n",
    "                    if excursion > max_excursion:\n",
    "                        max_excursion = excursion\n",
    "                        max_indices = (layer_idx, in_neuron_idx, out_neuron_idx)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"ERROR in find_max_excursion for connection: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return max_indices + (max_excursion,)\n",
    "\n",
    "def create_variable_speed_gif(output_folder, gif_name=\"spline_comparisons_variable_speed.gif\", max_duration=1.0, min_duration=0.1, fps=10):\n",
    "    \"\"\"\n",
    "    Genera una GIF da una cartella di immagini, con velocità variabile (più lenta all'inizio e più veloce alla fine).\n",
    "\n",
    "    Args:\n",
    "        output_folder (str): Percorso della cartella contenente le immagini.\n",
    "        gif_name (str): Nome del file GIF da salvare (default: \"spline_comparisons_variable_speed.gif\").\n",
    "        max_duration (float): Durata massima iniziale per ogni frame (in secondi, default: 1.0).\n",
    "        min_duration (float): Durata minima finale per ogni frame (in secondi, default: 0.1).\n",
    "        fps (int): Frame per secondo, usato per simulare durate variabili (default: 10).\n",
    "    \"\"\"\n",
    "    # Percorso completo del file GIF\n",
    "    gif_path = os.path.join(output_folder, gif_name)\n",
    "\n",
    "    # Recupera tutte le immagini dalla cartella\n",
    "    image_files = [\n",
    "        os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.endswith(\".png\")\n",
    "    ]\n",
    "\n",
    "    # Ordina le immagini in base al valore di x nel nome del file\n",
    "    def extract_x_from_filename(filename):\n",
    "        match = re.search(r\"_model_(\\d+)_vs\", filename)\n",
    "        return int(match.group(1)) if match else float('inf')  # Inf se il pattern non viene trovato\n",
    "\n",
    "    image_files.sort(key=extract_x_from_filename)\n",
    "\n",
    "    # Genera una lista di durate: più lenta all'inizio, più veloce alla fine (quadratica)\n",
    "    num_images = len(image_files)\n",
    "    durations = max_duration - (np.linspace(0, 1, num_images) ** 2) * (max_duration - min_duration)\n",
    "\n",
    "    # Crea la GIF con durate simulate tramite frame ripetuti\n",
    "    with imageio.get_writer(gif_path, mode=\"I\", fps=fps) as writer:\n",
    "        for image_file, duration in zip(image_files, durations):\n",
    "            # Calcola quante volte ripetere il frame per simulare la durata\n",
    "            repeat_count = max(1, int(duration * fps))  # Almeno una ripetizione\n",
    "            frame = imageio.imread(image_file)\n",
    "            for _ in range(repeat_count):\n",
    "                writer.append_data(frame)  # Aggiungi frame ripetuti\n",
    "\n",
    "    # Calcola la durata totale della GIF\n",
    "    total_duration = sum(durations)\n",
    "    print(f\"GIF creata con durata totale: {total_duration:.2f} secondi\")\n",
    "    print(f\"GIF salvata in: {gif_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def generate_spline_comparisons(\n",
    "    models, \n",
    "    layer_idx, \n",
    "    in_neuron_idx, \n",
    "    out_neuron_idx, \n",
    "    grid_range=(-1, 1), \n",
    "    output_folder=\"spline_comparisons\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera confronti delle spline per una specifica connessione tra due modelli consecutivi \n",
    "    e salva i plot in una cartella specificata.\n",
    "\n",
    "    Args:\n",
    "        models (list): Lista di modelli KAN.\n",
    "        layer_idx (int): Indice del livello da confrontare.\n",
    "        in_neuron_idx (int): Indice del neurone nel livello precedente.\n",
    "        out_neuron_idx (int): Indice del neurone nel livello successivo.\n",
    "        grid_range (tuple): Range dei valori per le x delle spline (default: (-1, 1)).\n",
    "        output_folder (str): Percorso della cartella di output in cui salvare i plot (default: \"spline_comparisons\").\n",
    "    \"\"\"\n",
    "    # Crea la cartella di output se non esiste\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Calcola i limiti delle y per il grafico\n",
    "    y_min, y_max = calculate_ylim(models, layer_idx, in_neuron_idx, out_neuron_idx, grid_range)\n",
    "    print(f\"Y-limits calcolati: {y_min}, {y_max}\")\n",
    "\n",
    "    # Itera sui modelli consecutivi e salva i plot\n",
    "    for i in range(len(models) - 1):\n",
    "        model1 = models[i]\n",
    "        model2 = models[i + 1]\n",
    "\n",
    "        # Percorso del file per il plot corrente\n",
    "        save_path = os.path.join(output_folder, f\"spline_comparison_model_{i+1}_vs_{i+2}.png\")\n",
    "        print(f\"Salvando il plot: {save_path}\")\n",
    "\n",
    "        # Genera e salva il plot\n",
    "        compare_splines_for_neuron(\n",
    "            model1=model1, \n",
    "            model2=model2, \n",
    "            layer_idx=layer_idx, \n",
    "            in_neuron_idx=in_neuron_idx, \n",
    "            out_neuron_idx=out_neuron_idx, \n",
    "            grid_range=grid_range, \n",
    "            plot_control_points=False, \n",
    "            model_index1=i+1, \n",
    "            model_index2=i+2, \n",
    "            save_path=save_path, \n",
    "            y_min=y_min, \n",
    "            y_max=y_max\n",
    "        )\n",
    "\n",
    "def compute_spline_inefficiency(\n",
    "    original_spline,\n",
    "    original_knots,\n",
    "    original_degree,\n",
    "    max_degree_reduction=999,\n",
    "    max_grid_reduction=999,\n",
    "    acceptable_mse=1e-4\n",
    "):\n",
    "    inefficiency_results = []\n",
    "    original_params = len(original_knots) - original_degree - 1\n",
    "    x = np.linspace(original_knots[0], original_knots[-1], 1000)\n",
    "    y_original = original_spline(x)\n",
    "\n",
    "    for degree_reduction in range(max_degree_reduction + 1):\n",
    "        new_degree = original_degree - degree_reduction\n",
    "        if new_degree < 1:\n",
    "            continue  # The degree must be at least 1\n",
    "\n",
    "        for grid_reduction in range(1, max_grid_reduction + 1):\n",
    "            # Calculate the number of internal knots\n",
    "            num_internal_knots = max(\n",
    "                len(original_knots) - 2 * (original_degree + 1) - grid_reduction * (degree_reduction + 1),\n",
    "                0\n",
    "            )\n",
    "            if num_internal_knots < 0:\n",
    "                continue  # Not enough internal knots\n",
    "\n",
    "            # Create the reduced internal knots\n",
    "            if num_internal_knots > 0:\n",
    "                internal_knots = np.linspace(\n",
    "                    original_knots[original_degree + 1],\n",
    "                    original_knots[-(original_degree + 1)],\n",
    "                    num_internal_knots\n",
    "                )\n",
    "            else:\n",
    "                internal_knots = np.array([])\n",
    "\n",
    "            try:\n",
    "                # Fit spline to the original data\n",
    "                if len(internal_knots) > 0:\n",
    "                    # For LSQUnivariateSpline, the knots should exclude the boundary knots\n",
    "                    # So we ensure that internal_knots are within the interval\n",
    "                    internal_knots = internal_knots[(internal_knots > original_knots[0]) & (internal_knots < original_knots[-1])]\n",
    "\n",
    "                    new_spline = LSQUnivariateSpline(x, y_original, t=internal_knots, k=new_degree)\n",
    "                else:\n",
    "                    # No internal knots, use UnivariateSpline which can handle this case\n",
    "                    new_spline = UnivariateSpline(x, y_original, k=new_degree)\n",
    "                y_new = new_spline(x)\n",
    "                mse = np.mean((y_original - y_new) ** 2)\n",
    "\n",
    "                # Number of coefficients\n",
    "                num_coeffs = len(new_spline.get_coeffs())\n",
    "                inefficiency = original_params - num_coeffs\n",
    "\n",
    "                if mse <= acceptable_mse:\n",
    "                    inefficiency_results.append({\n",
    "                        'inefficiency': inefficiency,\n",
    "                        'grid_size': len(new_spline.get_knots()),\n",
    "                        'degree': new_degree,\n",
    "                        'mse': mse,\n",
    "                        'spline': new_spline,\n",
    "                        'num_coeffs': num_coeffs\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    if not inefficiency_results:\n",
    "        # Nessuna configurazione valida trovata: comportati come se la nuova spline fosse la vecchia\n",
    "        return original_params, len(original_knots), original_degree, 0.0, original_spline, x, y_original\n",
    "\n",
    "    # Find the configuration with the minimal number of coefficients\n",
    "    optimal_result = min(inefficiency_results, key=lambda x: (x['num_coeffs'], x['inefficiency']))\n",
    "\n",
    "    new_spline = optimal_result['spline']\n",
    "\n",
    "    return optimal_result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specifica il percorso del modello salvato\n",
    "    model_path = \"results/results_None_SGD_lr0.01_5_3/LeNet300_Full/model/checkpoint_epoch_10.pth\"\n",
    "    \n",
    "    # Dettagli per ricreare il modello\n",
    "    model_class = KANLinearFullyConnected  # Classe del modello\n",
    "    model_args = {\n",
    "        \"layers_hidden\": [784, 300, 100, 62],  # Struttura del modello\n",
    "        \"grid_size\": 5,                      # Dimensione griglia\n",
    "        \"spline_order\": 3,                    # Ordine spline\n",
    "        \"scale_noise\": 0.1,\n",
    "        \"scale_base\": 1.0,\n",
    "        \"scale_spline\": 1.0,\n",
    "        \"base_activation\": torch.nn.ReLU,      # Funzione di attivazione\n",
    "        \"grid_eps\": 0.02,\n",
    "        \"grid_range\": [-1, 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d595f933-d77d-485f-9656-61253d9f3091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint trovati: da epoch 1 a epoch 20\n",
      "5 3\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "grid_size = 5 spline_order = 3\n",
      "5 3\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "grid_size = 5 spline_order = 3\n",
      "5 3\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "grid_size = 5 spline_order = 3\n",
      "5 3\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "5 3\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "5 3\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n",
      "grid_size = 5 spline_order = 3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for KANLinearFullyConnected:\n\tMissing key(s) in state_dict: \"layers.1.base_weight\", \"layers.1.spline_weight\", \"layers.1.spline_scaler\", \"layers.1.grid\", \"layers.2.base_weight\", \"layers.2.spline_weight\", \"layers.2.spline_scaler\", \"layers.2.grid\". \n\tsize mismatch for layers.0.base_weight: copying a param with shape torch.Size([62, 784]) from checkpoint, the shape in current model is torch.Size([300, 784]).\n\tsize mismatch for layers.0.spline_weight: copying a param with shape torch.Size([62, 784, 8]) from checkpoint, the shape in current model is torch.Size([300, 784, 8]).\n\tsize mismatch for layers.0.spline_scaler: copying a param with shape torch.Size([62, 784]) from checkpoint, the shape in current model is torch.Size([300, 784]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mload_models_from_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/results_None_SGD_lr0.01_5_3/LeNet300_OutputOnly/model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m, in \u001b[0;36mload_models_from_folder\u001b[0;34m(model_folder, model_class, model_args, max_workers)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Caricare i modelli in parallelo\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 81\u001b[0m     models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_model_for_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_numbers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumero di modelli caricati: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/KAN/anaconda3/envs/pykan-env/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/KAN/anaconda3/envs/pykan-env/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/KAN/anaconda3/envs/pykan-env/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/KAN/anaconda3/envs/pykan-env/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mload_models_from_folder.<locals>.load_model_for_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_for_epoch\u001b[39m(epoch):\n\u001b[1;32m     76\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 40\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, model_class, model_args)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Carica il checkpoint e accedi al model_state_dict\u001b[39;00m\n\u001b[1;32m     39\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Imposta in modalità di valutazione\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/KAN/anaconda3/envs/pykan-env/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for KANLinearFullyConnected:\n\tMissing key(s) in state_dict: \"layers.1.base_weight\", \"layers.1.spline_weight\", \"layers.1.spline_scaler\", \"layers.1.grid\", \"layers.2.base_weight\", \"layers.2.spline_weight\", \"layers.2.spline_scaler\", \"layers.2.grid\". \n\tsize mismatch for layers.0.base_weight: copying a param with shape torch.Size([62, 784]) from checkpoint, the shape in current model is torch.Size([300, 784]).\n\tsize mismatch for layers.0.spline_weight: copying a param with shape torch.Size([62, 784, 8]) from checkpoint, the shape in current model is torch.Size([300, 784, 8]).\n\tsize mismatch for layers.0.spline_scaler: copying a param with shape torch.Size([62, 784]) from checkpoint, the shape in current model is torch.Size([300, 784])."
     ]
    }
   ],
   "source": [
    "models = load_models_from_folder(\"results/results_None_SGD_lr0.01_5_3/LeNet300_OutputOnly/model\", model_class, model_args, max_workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5242731-ff3f-4a69-9b32-e872ffe9b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_spline = find_max_spline_difference(models[0], models[-1])\n",
    "layer_idx = max_spline[0]  \n",
    "in_neuron_idx = max_spline[1]\n",
    "out_neuron_idx = max_spline[2]\n",
    "grid_range = (-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc727ba9-882a-462e-8cea-d4771e459671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_folder = \"spline_comparisons\"\n",
    "generate_spline_comparisons(\n",
    "    models, \n",
    "    layer_idx, \n",
    "    in_neuron_idx, \n",
    "    out_neuron_idx, \n",
    "    grid_range=(-1, 1), \n",
    "    output_folder=output_folder\n",
    ")\n",
    "\n",
    "create_variable_speed_gif(output_folder, gif_name=\"spline_comparisons.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb125b-19c2-4db2-b1c8-b6afb0df55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Definizione della connessione specifica per il confronto\n",
    "layer_idx = 2  # Indice del layer\n",
    "in_neuron_idx = 72  # Indice del neurone precedente\n",
    "out_neuron_idx = 1  # Indice del neurone successivo\n",
    "grid_range = (-1, 1)  # Range dei valori della griglia\n",
    "\n",
    "compare_splines_for_neuron(models[0],  models[-1], layer_idx, in_neuron_idx, out_neuron_idx, grid_range=(-1, 1), plot_control_points=False, model_index1=1, model_index2=len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d852f08-5370-411c-ad03-f5fa83876bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_max_excursion(models[-1], grid_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41048d3c-8cb9-477e-aa08-55849ff4059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_max_excursion(models[1], grid_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc74f6-9196-44d5-ab96-4252ea2b62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione della connessione specifica per il confronto\n",
    "layer_idx = 2  # Indice del layer\n",
    "in_neuron_idx = 72  # Indice del neurone precedente\n",
    "out_neuron_idx = 2  # Indice del neurone successivo\n",
    "grid_range = (-1, 1)  # Range dei valori della griglia\n",
    "\n",
    "compare_splines_for_neuron(models[0],  models[-1], layer_idx, in_neuron_idx, out_neuron_idx, grid_range=(-1, 1), plot_control_points=False, model_index1=1, model_index2=len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f18675-1b6a-464f-ac48-c4982ef60c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tensor_data, mask = collect_all_neuron_statistics(models)\n",
    "stats = compute_statistics_on_gpu(tensor_data, mask)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac71a7-bfbd-430f-bd3c-01d538dc485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the data\n",
    "tensor_data, mask = collect_all_neuron_statistics(models)\n",
    "\n",
    "# Define the layer and model indices\n",
    "layer_idx = 1  # For example, the second layer\n",
    "model_idx = 0  # For example, the first model\n",
    "\n",
    "# Compute statistics for a specific layer and model\n",
    "stats_layer_model = compute_statistics_for_layer_and_model(tensor_data, mask, layer_idx, model_idx)\n",
    "print(f\"Statistics for layer {layer_idx} in model {model_idx}:\")\n",
    "for key, value in stats_layer_model.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Compute statistics for a specific layer across all models\n",
    "stats_layer_across_models = compute_statistics_for_layer_across_models(tensor_data, mask, layer_idx)\n",
    "print(f\"\\nStatistics for layer {layer_idx} across all models:\")\n",
    "for key, value in stats_layer_across_models.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71098a71-ec79-4c5c-9fc2-1430a0f850ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare the original spline and the optimized one\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define acceptable MSE\n",
    "acceptable_mse = 1e-2  # Adjust this value based on your requirements\n",
    "\n",
    "# Configurazione con molti più parametri\n",
    "original_degree = 10  # Grado più elevato per maggiore complessità\n",
    "original_knots = np.linspace(-1, 1, 300)  # Molti più nodi\n",
    "coefficients = np.sin(np.linspace(0, 8 * np.pi, len(original_knots) - original_degree - 1))  # Più complessa e oscillante\n",
    "\n",
    "# Crea la spline originale\n",
    "original_spline = BSpline(original_knots, coefficients, original_degree)\n",
    "\n",
    "# Call the modified function\n",
    "optimal_result = compute_spline_inefficiency(\n",
    "    original_spline,\n",
    "    original_knots,\n",
    "    original_degree,\n",
    "    acceptable_mse=acceptable_mse\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Risultati:\\n\", optimal_results)\n",
    "\n",
    "x = np.linspace(original_knots[0], original_knots[-1], 1000)\n",
    "y_original = original_spline(x)\n",
    "new_spline = optimal_result['spline']\n",
    "y_new = new_spline(x)\n",
    "\n",
    "# Calculate the actual MSE\n",
    "mse_effettivo = np.mean((y_original - y_new) ** 2)\n",
    "print(f\"MSE Effettivo: {mse_effettivo}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y_original, label='Spline Originale', color='blue')\n",
    "plt.plot(x, y_new, label='Spline Ottimizzata', color='red', linestyle='--')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Confronto tra Spline Originale e Ottimizzata')\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    print(f\"Numero di Coefficienti della Nuova Spline: {len(new_spline.get_coeffs())}\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d470a-8c09-4bc1-ac7e-3104a87b5bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
