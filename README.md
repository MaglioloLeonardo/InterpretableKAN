# ğŸ” Interpretable Deep Learning with Kolmogorov-Arnold Networks (KANs)

## ğŸš€ About This Repository
This repository explores **Kolmogorov-Arnold Networks (KANs)** in deep learning, focusing on their **interpretability and effectiveness** compared to traditional architectures. The project includes multiple experiments evaluating KANs in both **fully connected and convolutional settings**, with visualization techniques like **Grad-CAM** and **PCA** to better understand their decision-making process.

### **Key areas of investigation**
- ğŸ”¹ **Neural Network Design**: Comparing KAN-based architectures with standard deep learning models.
- ğŸ”¹ **Interpretability**: Using visualization techniques to analyze learned representations.
- ğŸ”¹ **Performance**: Benchmarking KANs on classification tasks (MNIST & EMNIST).
- ğŸ”¹ **Computational Trade-offs**: Assessing expressivity vs. efficiency.

---

## ğŸ“Œ Experiments

### ğŸ”¹ 1. Convolutional KANs vs. CNNs
**Goal:** Evaluate convolutional KANs (KaNet-5) against standard CNNs (LeNet-5) on EMNIST using **Grad-CAM** interpretability analysis.

âœ… KAN filters dynamically adapt to complex patterns.  
âœ… Grad-CAM shows KANs have broader, more flexible attention maps.  

#### **Grad-CAM Visualization**
![GradCAM](https://raw.githubusercontent.com/MaglioloLeonardo/InterpretableKAN/main/Images%20%26%20Videos/DemoGradCAMFeatureMAPExample.gif)

---

### ğŸ”¹ 2. Spline Evolution in KANs
**Goal:** Visualize how spline-based transformations evolve during training.

âœ… Splines adjust dynamically, offering localized feature adaptation.  
âœ… Unlike fixed activations, they provide smoother function approximation.  

#### **Visualization of Spline Evolution**
![Spline Evolution](https://raw.githubusercontent.com/MaglioloLeonardo/InterpretableKAN/main/Images%20%26%20Videos/DemoSplineEvolution.gif)

---

### ğŸ”¹ 3. Fully Connected KANs vs. MLPs
**Goal:** Compare standard MLPs (LeNet-300) with KAN-based models (KaNet-300) on MNIST to analyze performance and generalization.

âœ… KANs match or exceed standard networks while using fewer layers.  
âœ… Splines help reduce overfitting and improve feature representation.  

#### **MLP vs. KAN Representation**
![MLP vs KAN](https://raw.githubusercontent.com/MaglioloLeonardo/InterpretableKAN/main/Images%20%26%20Videos/MLP_vs_KAN.png)

---

### ğŸ”¹ 4. PCA-Based Feature Representation
**Goal:** Use PCA to compare how standard networks and KANs encode learned feature distributions.

#### **PCA Visualization**
![PCA](https://raw.githubusercontent.com/MaglioloLeonardo/InterpretableKAN/main/Images%20%26%20Videos/PCADemo.png)

---

## ğŸ“ˆ Key Takeaways
- âš¡ **Expressivity**: KANs model functions with more flexibility.
- ğŸ‘ **Interpretability**: PCA and Grad-CAM provide deeper insights.
- ğŸš€ **Scalability**: Balancing efficiency and computational cost.

---

## ğŸ“œ Future Work
- ğŸ“Š Apply KANs to CIFAR-10 & ImageNet.
- âš™ Optimize efficiency for real-time applications.
- ğŸ¤– Combine KANs with attention mechanisms.

